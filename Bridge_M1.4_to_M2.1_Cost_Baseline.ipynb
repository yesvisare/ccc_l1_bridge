{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge M1.4 → M2.1: Cost Reality + Caching Trade-off\n",
    "\n",
    "**Purpose:** Validate baseline costs before M2.1 caching implementation  \n",
    "**Source:** bridge_M1_4_to_M2_1.md  \n",
    "**Approach:** Local calculations only; no live API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Recap — M1 Shipped Baseline RAG + Metrics\n",
    "\n",
    "### Module 1 Accomplishments\n",
    "\n",
    "**M1.1 (Vector Databases):**\n",
    "- ✓ Pinecone index configured (dimension 1536, cosine metric)\n",
    "- ✓ Embeddings generated using OpenAI text-embedding-3-small\n",
    "- ✓ Semantic search with similarity scoring\n",
    "- ✓ 5 common vector DB failures debugged\n",
    "\n",
    "**M1.2 (Advanced Indexing):**\n",
    "- ✓ Hybrid search (dense + sparse vectors, 20-40% better recall)\n",
    "- ✓ Metadata filtering for domain-specific queries\n",
    "- ✓ Advanced index configurations tested\n",
    "- ✓ Cost-performance trade-offs documented\n",
    "\n",
    "**M1.3 (Document Processing):**\n",
    "- ✓ Multi-format parser (PDF, TXT, DOCX, MD)\n",
    "- ✓ Smart chunking strategies (size-based, semantic, sliding window)\n",
    "- ✓ Batch processing with error handling\n",
    "- ✓ Metadata extraction & enrichment\n",
    "\n",
    "**M1.4 (Query Pipeline):**\n",
    "- ✓ Complete 7-stage query pipeline\n",
    "- ✓ Query classification system\n",
    "- ✓ Cross-encoder reranking (20-40% quality improvement)\n",
    "- ✓ Production error handling (5 common failures)\n",
    "- ✓ Performance monitoring (latency, cost, quality)\n",
    "- ✓ Source attribution & streaming responses\n",
    "\n",
    "### Current State\n",
    "\n",
    "**Working RAG system with:**\n",
    "- Answers questions using indexed documents\n",
    "- Debugging capabilities for production failures\n",
    "- Performance measurement baseline\n",
    "\n",
    "**The Problem:** Every query processed fresh; no memory of previous answers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Baseline — Approximate Per-Query Cost Calculator\n\n**Baseline scale:** 10,000 queries/day  \n**Approach:** Local math using constants from bridge_M1_4_to_M2_1.md",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cost constants from bridge_M1_4_to_M2_1.md\nCOST_EMBEDDING_PER_QUERY = 0.0001    # OpenAI text-embedding-3-small\nCOST_LLM_PER_QUERY = 0.002            # LLM generation\nCOST_VECTOR_SEARCH_PER_QUERY = 0.007  # Pinecone vector search\n\n# Baseline scale\nQUERIES_PER_DAY = 10_000\n\n# Calculate daily costs\ndaily_embedding_cost = QUERIES_PER_DAY * COST_EMBEDDING_PER_QUERY\ndaily_llm_cost = QUERIES_PER_DAY * COST_LLM_PER_QUERY\ndaily_vector_search_cost = QUERIES_PER_DAY * COST_VECTOR_SEARCH_PER_QUERY\n\ndaily_total = daily_embedding_cost + daily_llm_cost + daily_vector_search_cost\nmonthly_total = daily_total * 30\n\n# Expected: Daily=$91.00, Monthly=$2,730\nprint(\"=\" * 50)\nprint(\"BASELINE COST CALCULATOR\")\nprint(\"=\" * 50)\nprint(f\"Scale: {QUERIES_PER_DAY:,} queries/day\")\nprint()\nprint(\"Daily Costs:\")\nprint(f\"  Embeddings:      ${daily_embedding_cost:>7.2f}\")\nprint(f\"  LLM Calls:       ${daily_llm_cost:>7.2f}\")\nprint(f\"  Vector Searches: ${daily_vector_search_cost:>7.2f}\")\nprint(f\"  {'─' * 30}\")\nprint(f\"  DAILY TOTAL:     ${daily_total:>7.2f}\")\nprint()\nprint(f\"MONTHLY TOTAL:     ${monthly_total:>7,.2f}\")\nprint()\nprint(f\"Per-query cost: ${daily_total / QUERIES_PER_DAY:.4f}\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Repeat-Rate Worksheet\n\n**Source:** bridge_M1_4_to_M2_1.md query repetition analysis  \n**Purpose:** Record assumed repeat percentages for caching estimation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\n\n# Query repetition rates from bridge_M1_4_to_M2_1.md\nrepeat_rate_assumptions = {\n    \"semantically_similar_pct\": {\n        \"min\": 30,\n        \"max\": 50,\n        \"assumed\": 40,\n        \"description\": \"Queries similar to previous queries\"\n    },\n    \"exact_near_exact_repeats_pct\": {\n        \"min\": 15,\n        \"max\": 25,\n        \"assumed\": 20,\n        \"description\": \"Exact or near-exact repeat queries\"\n    },\n    \"truly_unique_pct\": {\n        \"min\": 25,\n        \"max\": 40,\n        \"assumed\": 32.5,\n        \"description\": \"Completely unique questions\"\n    },\n    \"notes\": [\n        \"Source: Real RAG systems analysis from bridge_M1_4_to_M2_1.md\",\n        \"Assumed values used for caching projections\",\n        \"Edit 'assumed' values to test different scenarios\"\n    ]\n}\n\n# Save to JSON\nwith open('repeat_rate_assumptions.json', 'w') as f:\n    json.dump(repeat_rate_assumptions, f, indent=2)\n\n# Expected: JSON file created with repeat rate ranges\nprint(\"=\" * 50)\nprint(\"QUERY REPEAT-RATE ASSUMPTIONS\")\nprint(\"=\" * 50)\nprint()\nfor key, value in repeat_rate_assumptions.items():\n    if key != \"notes\":\n        print(f\"{value['description']}:\")\n        print(f\"  Range: {value['min']}%-{value['max']}%\")\n        print(f\"  Assumed: {value['assumed']}%\")\n        print()\n\nprint(\"Notes:\")\nfor note in repeat_rate_assumptions[\"notes\"]:\n    print(f\"  • {note}\")\nprint()\nprint(\"✓ Saved to: repeat_rate_assumptions.json\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Projected Savings — Caching What-If Table\n\n**Scenarios:** 0%, 30%, 50%, 70% cache hit rates  \n**Approach:** Simple cost reduction calculation at different hit rates",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cache hit rate scenarios\ncache_scenarios = [0, 30, 50, 70]\n\n# Baseline costs (from Section 2)\nbaseline_daily_cost = 91.00\nbaseline_monthly_cost = 2730.00\n\n# Cached query costs (minimal Redis lookup cost)\nCACHE_LOOKUP_COST = 0.0001  # Negligible Redis read cost\n\n# Expected: Table showing savings at 30%, 50%, 70% cache hit rates\nprint(\"=\" * 70)\nprint(\"CACHING WHAT-IF TABLE\")\nprint(\"=\" * 70)\nprint()\nprint(f\"{'Cache Hit Rate':<20} {'Daily Cost':<15} {'Monthly Cost':<15} {'Savings %':<15}\")\nprint(\"─\" * 70)\n\nresults = []\nfor hit_rate in cache_scenarios:\n    hit_rate_decimal = hit_rate / 100\n    \n    # Cached queries pay only lookup cost\n    cached_queries = QUERIES_PER_DAY * hit_rate_decimal\n    cache_cost = cached_queries * CACHE_LOOKUP_COST\n    \n    # Full-cost queries\n    full_cost_queries = QUERIES_PER_DAY * (1 - hit_rate_decimal)\n    full_cost = full_cost_queries * (baseline_daily_cost / QUERIES_PER_DAY)\n    \n    daily_cost = cache_cost + full_cost\n    monthly_cost = daily_cost * 30\n    savings_pct = ((baseline_daily_cost - daily_cost) / baseline_daily_cost) * 100\n    \n    results.append({\n        \"hit_rate\": hit_rate,\n        \"daily_cost\": daily_cost,\n        \"monthly_cost\": monthly_cost,\n        \"savings_pct\": savings_pct\n    })\n    \n    if hit_rate == 0:\n        print(f\"{hit_rate}% (baseline){'':<7} ${daily_cost:<14.2f} ${monthly_cost:<14,.2f} {'-':<15}\")\n    else:\n        print(f\"{hit_rate}%{'':<17} ${daily_cost:<14.2f} ${monthly_cost:<14,.2f} {savings_pct:<14.1f}%\")\n\nprint(\"=\" * 70)\nprint()\nprint(\"KEY INSIGHTS:\")\nprint(f\"  • 30% cache hit rate → Save ~${baseline_monthly_cost - results[1]['monthly_cost']:.0f}/month\")\nprint(f\"  • 50% cache hit rate → Save ~${baseline_monthly_cost - results[2]['monthly_cost']:.0f}/month\")\nprint(f\"  • 70% cache hit rate → Save ~${baseline_monthly_cost - results[3]['monthly_cost']:.0f}/month\")\nprint()\nprint(\"Source: bridge_M1_4_to_M2_1.md — Caching savings: 30-70% reduction\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Risks — Freshness Trade-off\n\n**Trade-off Assessment:** HIGH  \n**Source:** bridge_M1_4_to_M2_1.md\n\n### Critical Limitation: Data Freshness Loss\n\n**The Trade-off:**  \n\"You gain speed and cost savings, but you lose data freshness.\"\n\n**When caching is WRONG:**\n- ❌ Knowledge base updates every 5 minutes\n- ❌ Real-time data requirements (stock prices, live metrics)\n- ❌ Rapidly changing content (news, social feeds)\n- ❌ Compliance requires latest data (regulatory, legal)\n\n**When caching makes sense:**\n- ✓ Stable documentation (API docs, how-to guides)\n- ✓ Historical data (archives, past reports)\n- ✓ FAQ-style content (policies, procedures)\n- ✓ Acceptable staleness window (hourly/daily updates OK)\n\n### Implementation Risks\n\n**1. Cache Invalidation (The Hard Problem)**\n- Challenge: \"Knowing when to refresh\"\n- Strategies: TTL (time-based), Event-based, LRU eviction\n- Risk: Stale answers for updated content\n\n**2. Cache Stampede**\n- Challenge: Many requests for expired cache key simultaneously\n- Impact: Sudden load spike when cache expires\n- Mitigation: Request coalescing (covered in M2.1)\n\n**3. Cache Warming**\n- Challenge: Cold cache = no savings initially\n- Reality: Takes time to build up hit rate\n- Expectation: 40-60% hit rate after warm-up period\n\n### Decision Framework\n\n**Ask before implementing caching:**\n\n1. What's our acceptable staleness window?\n   - Minutes? Caching risky\n   - Hours? Caching viable with short TTL\n   - Days? Caching strong candidate\n\n2. What's our update frequency?\n   - Continuous? Caching problematic\n   - Hourly/Daily? Caching works with proper TTL\n   - Weekly/Monthly? Caching ideal\n\n3. What's our cost/freshness priority?\n   - Freshness > Cost: Skip caching, optimize prompts instead\n   - Cost > Freshness: Caching appropriate with monitoring\n\n### Bottom Line\n\n**Caching is NOT free.** You trade data freshness for cost savings.  \nM2.1 will show you HOW to implement caching.  \nThis section shows you WHEN to implement it.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Call-Forward to M2.1 — Caching Goals & Invalidation Checklist\n\n**Next:** M2.1 Caching Strategies for Cost Reduction  \n**Duration:** 38 min video + 60-90 min hands-on\n\n### M2.1 Implementation Goals\n\n**Multi-layer Cache Architecture:**\n1. **Response Cache** — Complete answers (highest savings)\n2. **Semantic Cache** — Similar query matching (40-60% hit rate target)\n3. **Embedding Cache** — Reuse vector representations\n4. **Context Cache** — Retrieved document chunks\n\n**Technologies:**\n- Redis for response cache with SHA-256 hashing\n- Faiss for semantic similarity cache\n- Request coalescing for cache stampede protection\n\n**Expected Performance:**\n- 40-60% of queries served from cache\n- 50-200ms cached response time (vs 300-500ms full pipeline)\n- 30-70% cost reduction at scale\n\n### Pre-M2.1 Checklist\n\n☐ **Baseline metrics captured**  \n   → Run Section 2 calculator to confirm $91/day baseline  \n   → Document current per-query cost ($0.0091)\n\n☐ **Repeat rate estimated**  \n   → Review Section 3 assumptions (30-50% similar queries)  \n   → Adjust JSON if your query patterns differ\n\n☐ **Savings scenarios reviewed**  \n   → Study Section 4 what-if table  \n   → Identify target cache hit rate (30%, 50%, or 70%)\n\n☐ **Trade-off decision made**  \n   → Section 5 decision framework completed  \n   → Staleness window defined (hours? days?)  \n   → Cost vs freshness priority clarified\n\n☐ **Ready for implementation**  \n   → M1.4 query pipeline working reliably  \n   → Performance monitoring in place  \n   → Test environment prepared for caching layer\n\n### Cache Invalidation Strategy Checklist\n\n**Before implementing caching, define:**\n\n☐ **TTL (Time-To-Live)**  \n   - How long should cached answers remain valid?  \n   - Recommendation: Start with 1 hour, adjust based on update frequency\n\n☐ **Event-based Invalidation**  \n   - What events require cache clearing?  \n   - Examples: Document updates, index rebuilds, config changes\n\n☐ **LRU (Least Recently Used) Eviction**  \n   - What's max cache size?  \n   - What happens when cache fills up?\n\n☐ **Monitoring & Alerting**  \n   - Track cache hit rate (target: 40-60%)  \n   - Alert on cache misses spike (indicates invalidation issues)  \n   - Monitor staleness metrics (time since cache entry created)\n\n### Ready?\n\nRun all cells in this notebook to:\n1. ✓ Validate baseline costs\n2. ✓ Record repeat-rate assumptions  \n3. ✓ Project caching savings  \n4. ✓ Review freshness trade-offs  \n5. ✓ Complete pre-M2.1 checklist\n\n**Then proceed to M2.1: Caching Strategies for Cost Reduction**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}