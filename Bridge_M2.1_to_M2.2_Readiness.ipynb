{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge M2.1 → M2.2: Cache-Miss Cost Focus\n",
    "\n",
    "**Duration:** 5-10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Run Locally (Windows)\n",
    "\n",
    "```powershell\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "Linux/Mac:\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "You've completed M2.1 and built a multi-layer Redis cache reducing RAG costs by 30-70%. But 60% of queries still miss the cache, hitting the full pipeline at $0.0021 per query.\n",
    "\n",
    "**The shift:** From optimizing cache hits (M2.1) to optimizing cache misses (M2.2). This bridge validates your M2.1 completion and prepares you to add prompt optimization, reducing cache-miss costs by another 30-50%.\n",
    "\n",
    "**Why it matters:** Combined savings of 50-70% total cost reduction make RAG systems production-viable. Without baseline metrics from M2.1, you can't prove ROI in M2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Covered\n",
    "\n",
    "**Delta from M2.1 to M2.2:**\n",
    "- Cache hit rate thresholds (when caching overhead exceeds savings)\n",
    "- Cost baseline establishment for compound optimization measurement\n",
    "- Query diversity as a strategy selector (compression vs. semantic tuning)\n",
    "- Production failure documentation as interview evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Completing This Notebook\n",
    "\n",
    "You will have verified:\n",
    "- ✓ Cache hit rate ≥30% (or documented mitigation strategy)\n",
    "- ✓ Cost savings baseline recorded for ROI tracking\n",
    "- ✓ All 5 production failures documented with fixes\n",
    "- ✓ Query diversity metrics guide M2.2 optimization focus\n",
    "- ✓ Readiness to add prompt optimization without breaking existing cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context in Track\n",
    "\n",
    "**Bridge:** M2.1 Caching Strategies → M2.2 Prompt Optimization & Model Selection\n",
    "\n",
    "**Module:** M2 (Cost Optimization)\n",
    "\n",
    "**Learning path:** Caching (passive cost reduction) → Prompt engineering (active cost reduction per query)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: M2.1 Accomplishments\n",
    "\n",
    "### What You Built in M2.1\n",
    "\n",
    "✓ **Multi-Layer Redis Cache System**  \n",
    "Four layers (response, semantic, embedding, context) that reduce RAG costs by 30-70%.\n",
    "\n",
    "✓ **Cache Invalidation Strategy**  \n",
    "TTL, event-based, and LRU policies balancing freshness vs. cost savings.\n",
    "\n",
    "✓ **Debugged 5 Production Failures**\n",
    "1. Cache stampede on cold start\n",
    "2. Stale data after updates\n",
    "3. Redis memory overflow (OOM)\n",
    "4. Hash collisions\n",
    "5. Connection timeouts\n",
    "\n",
    "✓ **Query Diversity Analysis**  \n",
    "Learned when caching works (similarity >30%) and when to skip it (>90% diversity).\n",
    "\n",
    "---\n",
    "\n",
    "### The Cache Miss Problem\n",
    "\n",
    "**Your cache hit rate:** 40% (typical)  \n",
    "**Cache miss rate:** 60% of queries still hit full pipeline\n",
    "\n",
    "**Cost calculation:**\n",
    "- 10,000 queries/day\n",
    "- 6,000 cache misses/day\n",
    "- Cost per miss: $0.0021\n",
    "- **Daily cost:** $12.60 = **$378/month**\n",
    "\n",
    "**M2.2 Goal:** Reduce cache miss costs by 30-50% through prompt optimization.\n",
    "\n",
    "**Combined savings:** 40% (caching) + 30-50% (prompt optimization) = **50-70% total cost reduction**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check #1: Cache Hit Rate\n",
    "\n",
    "**Requirement:** Redis cache operational with >30% hit rate\n",
    "\n",
    "**Why:** Low hit rate (<30%) means caching overhead exceeds savings; prompt optimization becomes critical.\n",
    "\n",
    "---\n",
    "\n",
    "**What this cell does:** Attempts to read Redis stats via `redis-cli`, falls back to manual input if unavailable, or creates a stub file. The skip guard ensures the notebook runs offline without live Redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: cache_hit_rate >= 0.30\n",
    "# Offline-friendly: Falls back to manual input or stub file\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "SKIP_REDIS = os.environ.get('SKIP_REDIS', 'false').lower() == 'true'\n",
    "\n",
    "# Option 1: Try parsing Redis stats (skip guard for offline mode)\n",
    "def get_redis_hit_rate():\n",
    "    if SKIP_REDIS:\n",
    "        print(\"⊘ Skipping Redis check (SKIP_REDIS=true)\")\n",
    "        return None\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['redis-cli', 'INFO', 'stats'], \n",
    "                              capture_output=True, text=True, timeout=2)\n",
    "        if result.returncode == 0:\n",
    "            lines = result.stdout.split('\\n')\n",
    "            hits = misses = 0\n",
    "            for line in lines:\n",
    "                if 'keyspace_hits:' in line:\n",
    "                    hits = int(line.split(':')[1])\n",
    "                if 'keyspace_misses:' in line:\n",
    "                    misses = int(line.split(':')[1])\n",
    "            if hits + misses > 0:\n",
    "                return hits / (hits + misses)\n",
    "    except Exception as e:\n",
    "        print(f\"⊘ Redis not available: {e}\")\n",
    "    return None\n",
    "\n",
    "# Option 2: Manual input fallback\n",
    "def manual_input_hit_rate():\n",
    "    print(\"Enter your cache hit rate (0.0-1.0) or press Enter to use stub:\")\n",
    "    try:\n",
    "        user_input = input().strip()\n",
    "        if user_input:\n",
    "            return float(user_input)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Option 3: Stub from file (offline-safe)\n",
    "def stub_hit_rate():\n",
    "    stub_file = 'cache_metrics_stub.json'\n",
    "    if os.path.exists(stub_file):\n",
    "        with open(stub_file) as f:\n",
    "            data = json.load(f)\n",
    "            return data.get('cache_hit_rate', 0.40)\n",
    "    # Create stub if missing\n",
    "    stub_data = {'cache_hit_rate': 0.40, 'note': 'Replace with actual metrics'}\n",
    "    with open(stub_file, 'w') as f:\n",
    "        json.dump(stub_data, f, indent=2)\n",
    "    print(f\"✓ Created {stub_file} with default hit rate 0.40\")\n",
    "    return 0.40\n",
    "\n",
    "# Try methods in order\n",
    "hit_rate = get_redis_hit_rate()\n",
    "if hit_rate is None:\n",
    "    hit_rate = stub_hit_rate()  # Skip manual input in automated environments\n",
    "\n",
    "# Validate\n",
    "print(f\"\\n✓ Cache Hit Rate: {hit_rate:.1%}\")\n",
    "if hit_rate >= 0.30:\n",
    "    print(\"✓ PASS: Hit rate meets minimum threshold (>=30%)\")\n",
    "else:\n",
    "    print(f\"⚠ WARNING: Hit rate {hit_rate:.1%} < 30%\")\n",
    "    print(\"  → Return to M2.1 Augmented [14:30] for semantic cache tuning\")\n",
    "    print(\"  → Prompt optimization will carry more load in M2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check #2: Cost Savings Baseline\n",
    "\n",
    "**Requirement:** Analytics showing `cost_savings_vs_baseline` with 30-40% reduction\n",
    "\n",
    "**Why:** Baseline metrics let you measure compound savings when adding prompt optimization; no baseline = can't prove ROI.\n",
    "\n",
    "---\n",
    "\n",
    "**What this cell does:** Loads or creates a cost analytics JSON file with baseline and current costs. Validates the `cost_savings_vs_baseline` field exists for ROI tracking in M2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: cost_savings_vs_baseline field exists showing 30-70% reduction\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "stub_file = 'cost_analytics_stub.json'\n",
    "\n",
    "# Check if analytics file exists\n",
    "if os.path.exists(stub_file):\n",
    "    with open(stub_file) as f:\n",
    "        analytics = json.load(f)\n",
    "    print(f\"✓ Found {stub_file}\")\n",
    "else:\n",
    "    # Create stub template (offline-safe)\n",
    "    analytics = {\n",
    "        \"baseline_cost_per_day\": 21.00,\n",
    "        \"current_cost_per_day\": 12.60,\n",
    "        \"cost_savings_vs_baseline\": 0.40,\n",
    "        \"note\": \"Replace with actual analytics data\"\n",
    "    }\n",
    "    with open(stub_file, 'w') as f:\n",
    "        json.dump(analytics, f, indent=2)\n",
    "    print(f\"✓ Created {stub_file} with template data\")\n",
    "\n",
    "# Validate required field\n",
    "if 'cost_savings_vs_baseline' in analytics:\n",
    "    savings = analytics['cost_savings_vs_baseline']\n",
    "    baseline = analytics.get('baseline_cost_per_day', 0)\n",
    "    current = analytics.get('current_cost_per_day', 0)\n",
    "    \n",
    "    print(f\"\\n✓ Baseline cost/day: ${baseline:.2f}\")\n",
    "    print(f\"✓ Current cost/day: ${current:.2f}\")\n",
    "    print(f\"✓ Cost savings: {savings:.1%}\")\n",
    "    \n",
    "    if 0.30 <= savings <= 0.70:\n",
    "        print(\"✓ PASS: Savings within expected range (30-70%)\")\n",
    "    else:\n",
    "        print(f\"⚠ NOTE: Savings {savings:.1%} outside typical 30-70% range\")\n",
    "else:\n",
    "    print(\"✗ FAIL: 'cost_savings_vs_baseline' field missing\")\n",
    "    print(f\"  → Add this field to {stub_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check #3: Failures Documented\n",
    "\n",
    "**Requirement:** All 5 common failures documented with fixes\n",
    "\n",
    "**Why:** Prevents 4+ hours debugging same issues in M2.2 when caching interacts with optimized prompts; portfolio evidence.\n",
    "\n",
    "**The 5 Failures:**\n",
    "1. Cache stampede on cold start\n",
    "2. Stale data after updates\n",
    "3. Redis memory overflow (OOM)\n",
    "4. Hash collisions\n",
    "5. Connection timeouts\n",
    "\n",
    "---\n",
    "\n",
    "**What this cell does:** Searches for failure documentation in README or dedicated files. Creates a template if missing. Validates all 5 failure types are documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: File or README documenting all 5 failures + fixes\n",
    "\n",
    "import os\n",
    "\n",
    "# Check for documentation files\n",
    "doc_files = ['failures_documentation.md', 'README.md', 'FAILURES.md']\n",
    "stub_file = 'failures_documentation.md'\n",
    "\n",
    "required_failures = [\n",
    "    'cache stampede',\n",
    "    'stale data',\n",
    "    'memory overflow',\n",
    "    'hash collision',\n",
    "    'connection timeout'\n",
    "]\n",
    "\n",
    "found_file = None\n",
    "for f in doc_files:\n",
    "    if os.path.exists(f):\n",
    "        with open(f, 'r') as file:\n",
    "            content = file.read().lower()\n",
    "            found_file = f\n",
    "            break\n",
    "\n",
    "if found_file:\n",
    "    print(f\"✓ Found documentation: {found_file}\")\n",
    "    \n",
    "    # Check for all 5 failures\n",
    "    found_count = sum(1 for failure in required_failures if failure in content)\n",
    "    \n",
    "    print(f\"\\n✓ Failures documented: {found_count}/5\")\n",
    "    for failure in required_failures:\n",
    "        status = \"✓\" if failure in content else \"✗\"\n",
    "        print(f\"  {status} {failure.title()}\")\n",
    "    \n",
    "    if found_count >= 5:\n",
    "        print(\"\\n✓ PASS: All 5 failures documented\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ NOTE: Only {found_count}/5 failures found in documentation\")\n",
    "else:\n",
    "    # Create stub template\n",
    "    print(f\"⊘ No documentation found. Creating {stub_file} template...\")\n",
    "    \n",
    "    template = \"\"\"# Cache Failures & Fixes\n",
    "\n",
    "## 1. Cache Stampede on Cold Start\n",
    "**Problem:** [Describe the issue]\n",
    "**Fix:** [Your solution]\n",
    "\n",
    "## 2. Stale Data After Updates\n",
    "**Problem:** [Describe the issue]\n",
    "**Fix:** [Your solution]\n",
    "\n",
    "## 3. Redis Memory Overflow (OOM)\n",
    "**Problem:** [Describe the issue]\n",
    "**Fix:** [Your solution]\n",
    "\n",
    "## 4. Hash Collisions\n",
    "**Problem:** [Describe the issue]\n",
    "**Fix:** [Your solution]\n",
    "\n",
    "## 5. Connection Timeouts\n",
    "**Problem:** [Describe the issue]\n",
    "**Fix:** [Your solution]\n",
    "\"\"\"\n",
    "    \n",
    "    with open(stub_file, 'w') as f:\n",
    "        f.write(template)\n",
    "    \n",
    "    print(f\"✓ Created {stub_file} template\")\n",
    "    print(f\"⚠ ACTION REQUIRED: Fill in problem descriptions and fixes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check #4: Query Diversity Metric\n",
    "\n",
    "**Requirement:** Query diversity calculated from logs (CSV/JSON)\n",
    "\n",
    "**Why:** Determines M2.2 optimization strategy:\n",
    "- High diversity (>70%): Focus on prompt compression\n",
    "- Low diversity (<30%): Focus on semantic cache tuning\n",
    "\n",
    "---\n",
    "\n",
    "**What this cell does:** Searches for query diversity metrics in JSON or CSV format. Creates a stub if missing. Uses diversity score to recommend M2.2 optimization focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: CSV or JSON with query diversity distribution\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Check for diversity metrics files\n",
    "metric_files = ['query_diversity.json', 'query_diversity.csv', 'diversity_metrics.json']\n",
    "stub_file = 'query_diversity.json'\n",
    "\n",
    "found = False\n",
    "diversity = 0.45  # default\n",
    "\n",
    "for f in metric_files:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"✓ Found: {f}\")\n",
    "        \n",
    "        if f.endswith('.json'):\n",
    "            with open(f) as file:\n",
    "                data = json.load(file)\n",
    "                diversity = data.get('diversity_score', data.get('average_diversity', 0.45))\n",
    "                print(f\"\\n✓ Diversity score: {diversity:.1%}\")\n",
    "        elif f.endswith('.csv'):\n",
    "            with open(f) as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                rows = list(reader)\n",
    "                print(f\"\\n✓ Found {len(rows)} diversity records\")\n",
    "        \n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    # Create stub (offline-safe)\n",
    "    print(f\"⊘ No diversity metrics found. Creating {stub_file} template...\")\n",
    "    \n",
    "    stub_data = {\n",
    "        \"diversity_score\": 0.45,\n",
    "        \"total_queries\": 1000,\n",
    "        \"unique_patterns\": 450,\n",
    "        \"similarity_distribution\": {\n",
    "            \"0-30%\": 0.20,\n",
    "            \"30-70%\": 0.50,\n",
    "            \"70-100%\": 0.30\n",
    "        },\n",
    "        \"note\": \"Replace with actual query diversity analysis\"\n",
    "    }\n",
    "    \n",
    "    with open(stub_file, 'w') as f:\n",
    "        json.dump(stub_data, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Created {stub_file} with template data\")\n",
    "    diversity = stub_data['diversity_score']\n",
    "\n",
    "# Strategy recommendation\n",
    "print(\"\\n--- M2.2 Strategy Recommendation ---\")\n",
    "if diversity > 0.70:\n",
    "    print(\"⚠ High diversity (>70%)\")\n",
    "    print(\"  → Focus: Prompt compression in M2.2\")\n",
    "    print(\"  → Reason: Low cache hit potential, optimize each query\")\n",
    "elif diversity < 0.30:\n",
    "    print(\"✓ Low diversity (<30%)\")\n",
    "    print(\"  → Focus: Semantic cache tuning\")\n",
    "    print(\"  → Reason: High cache hit potential, maximize cache efficiency\")\n",
    "else:\n",
    "    print(\"✓ Medium diversity (30-70%)\")\n",
    "    print(\"  → Focus: Balanced approach (caching + prompt optimization)\")\n",
    "    print(\"  → Reason: Both strategies contribute significantly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call-Forward: M2.2 Preview\n",
    "\n",
    "### What's Next in M2.2: Prompt Optimization & Model Selection\n",
    "\n",
    "You'll add three capabilities to reduce cache miss costs by 30-50%:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. RAG-Specific Prompt Engineering\n",
    "**Goal:** Reduce token usage 30-50% with 7 optimization templates  \n",
    "**Trade-off:** Trading context/verbosity for cost savings  \n",
    "**Technique:** A/B test templates to find quality-cost sweet spot\n",
    "\n",
    "#### 2. Intelligent Model Routing\n",
    "**Goal:** Route simple → cheap models (GPT-3.5), complex → premium (GPT-4)  \n",
    "**Trade-off:** Balancing cost vs capability  \n",
    "**Risk:** Wrong routing = overpaying or poor answers\n",
    "\n",
    "#### 3. Token Optimization Techniques\n",
    "**Goal:** Smart truncation, compression, summarization to stay under token limits  \n",
    "**Trade-off:** Risking context loss if too aggressive  \n",
    "**Challenge:** When is 140 tokens enough vs. needing full 350?\n",
    "\n",
    "---\n",
    "\n",
    "### Critical Heads-Up\n",
    "\n",
    "**Aggressive prompt optimization can degrade answer quality.**\n",
    "\n",
    "When you cut a prompt from 350 → 140 tokens, you're removing context and nuance.\n",
    "\n",
    "**The sweet spot:** 30-40% token reduction with <5% quality degradation.\n",
    "\n",
    "M2.2 teaches you to optimize without breaking user trust—measuring quality alongside cost.\n",
    "\n",
    "---\n",
    "\n",
    "### The Question for M2.2\n",
    "\n",
    "**\"How do you optimize prompts to cut costs 30-50% without degrading answer quality?\"**\n",
    "\n",
    "**Technical preview:**\n",
    "- Use `tiktoken` for token counting\n",
    "- Implement template-based optimization with A/B testing\n",
    "- Build model router using complexity scoring\n",
    "\n",
    "**Combined result:** 50-70% total cost reduction (caching + prompt optimization)\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated time:** 40 min video + 60-90 min hands-on\n",
    "\n",
    "**Ready for M2.2!** ✓"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
