{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge M2.3 → M2.4: Observability to Self-Healing\n",
    "\n",
    "**Duration:** 8-10 min | **Module:** 2 - Cost Optimization  \n",
    "**Transition:** M2.3 (Production Monitoring) → M2.4 (Error Handling & Reliability)\n",
    "\n",
    "---\n",
    "\n",
    "## Run Locally\n",
    "\n",
    "**Windows:**\n",
    "```powershell\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "**Linux/Mac:**\n",
    "```bash\n",
    "PYTHONPATH=$PWD jupyter notebook\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This bridge validates your M2.3 observability infrastructure before advancing to M2.4 self-healing patterns. You've built monitoring that shows WHEN failures occur; M2.4 will teach your system to recover automatically from those failures. Without working metrics, alerts, and correlation logging, you cannot measure whether retries and circuit breakers are actually reducing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Covered\n",
    "\n",
    "**Validation Delta (M2.3 → M2.4):**\n",
    "- Baseline error rate measurement (current state before implementing resilience)\n",
    "- Alert infrastructure for circuit breaker state transitions\n",
    "- Log correlation requirements for tracing retry attempts\n",
    "- Metric endpoints as prerequisites for measuring error handling effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Completing\n",
    "\n",
    "You will be able to:\n",
    "- Verify Prometheus is scraping your RAG pipeline metrics at <30s intervals\n",
    "- Confirm Grafana dashboards display p95 latency, error rate, cache hit rate, and cost metrics\n",
    "- Validate 3+ alert rules are configured and can trigger notifications\n",
    "- Trace full request lifecycles using correlation IDs in structured logs\n",
    "- Document baseline error rate (current ~0.5-2%) for comparison after M2.4 (target <0.1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context in Track\n",
    "\n",
    "**Bridge: Module 2.3 → Module 2.4**\n",
    "\n",
    "**Previous (M2.3):** Production Monitoring & Observability  \n",
    "**Current Bridge:** Readiness validation for self-healing capabilities  \n",
    "**Next (M2.4):** Error Handling & Reliability (retries, circuit breakers, graceful degradation)\n",
    "\n",
    "**Module 2 Progress:** 3 of 4 complete (Caching, Prompt Optimization, Monitoring) → Resilience next\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: M2.3 Accomplishments Recap\n",
    "\n",
    "### What You Built in M2.3\n",
    "\n",
    "Congratulations! You completed M2.3 and built production-grade observability that most systems take months to implement properly.\n",
    "\n",
    "#### ✓ 1. Complete Observability Stack\n",
    "- **Set up:** Prometheus + Grafana monitoring infrastructure from scratch\n",
    "- **Tracking:** 8-10 production metrics including:\n",
    "  - Latency percentiles (p50, p95, p99)\n",
    "  - Cache hit rates\n",
    "  - Cost per query\n",
    "  - Error rates\n",
    "- **Update frequency:** Real-time dashboards refreshing every 15 seconds\n",
    "\n",
    "#### ✓ 2. Production-Grade Alerting\n",
    "- **Alert rules configured:**\n",
    "  - Rate limit headroom <20%\n",
    "  - p95 latency >500ms sustained\n",
    "  - Error rate >1% for 5 minutes\n",
    "- **Delivery:** Slack/email notifications tested and tuned\n",
    "- **Result:** Alerts fire on actual problems, avoiding alert fatigue\n",
    "\n",
    "#### ✓ 3. Metric Cardinality Management\n",
    "- **Problem solved:** Unbounded labels crash Prometheus\n",
    "- **Debugged:** Cardinality explosion (2GB RAM usage)\n",
    "- **Fixed:** Removed high-cardinality labels (user IDs), implemented proper label design\n",
    "- **Learning:** Use categories, not IDs, in metric labels\n",
    "\n",
    "#### ✓ 4. Structured Logging with Metrics\n",
    "- **Implementation:** JSON logging with correlation via request_id and query_id\n",
    "- **Benefit:** Jump from Grafana alert (symptom) to logs (root cause) in <60 seconds\n",
    "- **Impact:** MTTR reduced from hours to minutes\n",
    "\n",
    "### The Impact\n",
    "\n",
    "**Before M2.3:** Production incidents took hours to diagnose  \n",
    "**After M2.3:**\n",
    "- Detect problems: 1-2 minutes\n",
    "- Get debugging context: 5 minutes\n",
    "- Find root cause: Minutes (was hours)\n",
    "\n",
    "---\n",
    "\n",
    "### Why M2.4 Matters: From Visibility to Resilience\n",
    "\n",
    "**The reality:** Monitoring tells you THAT something is wrong. It doesn't prevent failures or auto-recover.\n",
    "\n",
    "#### Real Incident Example\n",
    "\n",
    "Perfect visibility, zero resilience:\n",
    "- **2:47 AM:** Alert fires: \"OpenAI rate limit at 95%\"\n",
    "- **2:48 AM:** Alert fires: \"p95 latency >800ms\"\n",
    "- **2:49 AM:** Alert fires: \"Error rate >5%\"\n",
    "- **Result:** 150 queries failed before manual intervention\n",
    "\n",
    "#### Cost of Brittleness\n",
    "\n",
    "**Revenue Impact:**\n",
    "- 150 failed queries × $20 avg = $3,000 revenue risk\n",
    "- 5% user churn = 7-8 lost customers\n",
    "- 1 negative review = 50-200 potential customers turned away\n",
    "\n",
    "**Time Cost:**\n",
    "- 3 AM wake-up + degraded performance\n",
    "- Manual recovery: 15-30 min per incident\n",
    "- Post-incident debugging: 2-4 hours\n",
    "- **Total:** ~6 hours @ $100/hr = $600 per incident\n",
    "\n",
    "**Reputation:**\n",
    "- Users lose trust after 2-3 failures\n",
    "- Support ticket spike ($25-50 each)\n",
    "- Team morale drops\n",
    "\n",
    "#### M2.4 Goal: Self-Healing Systems\n",
    "\n",
    "Turn a system that *alerts when it breaks* into one that *fixes itself and only alerts when human intervention is truly needed*.\n",
    "\n",
    "**M2.4 capabilities:**\n",
    "- Retry transient failures (API timeouts, rate limits)\n",
    "- Circuit breakers prevent cascading failures\n",
    "- Graceful degradation when dependencies fail\n",
    "- Request queuing during temporary overload\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Validation Check 1 - Prometheus Scrape Target\n",
    "\n",
    "### ✓ Check: Prometheus Scraping Your RAG Pipeline\n",
    "\n",
    "**What to verify:**\n",
    "- Prometheus targets show your app as \"State: UP\"\n",
    "- Last scrape timestamp <30 seconds ago\n",
    "- `/metrics` endpoint returns valid Prometheus metrics\n",
    "\n",
    "**Why this matters for M2.4:**\n",
    "- Need baseline error rate (current ~0.5-2%) to measure improvement\n",
    "- Target error rate after M2.4: <0.1%\n",
    "- Cannot measure retry effectiveness without working metrics\n",
    "\n",
    "**Success criteria:**\n",
    "- `http://localhost:9090/targets` shows app as UP\n",
    "- Metrics endpoint accessible and returning data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Check 1:** Attempts to contact Prometheus (localhost:9090) and your app metrics endpoint (localhost:8000). If services are offline, displays stub messages with validation steps instead of failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def check_metrics_endpoint():\n",
    "    \"\"\"Check if /metrics endpoint is accessible and returning data\"\"\"\n",
    "    \n",
    "    metrics_url = \"http://localhost:8000/metrics\"\n",
    "    prometheus_url = \"http://localhost:9090/targets\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CHECK 1: Prometheus /metrics Endpoint\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check app metrics endpoint (offline-friendly)\n",
    "    try:\n",
    "        response = requests.get(metrics_url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            metrics_count = len([line for line in response.text.split('\\n') if line and not line.startswith('#')])\n",
    "            print(f\"✓ App /metrics endpoint: ACCESSIBLE\")\n",
    "            print(f\"  - URL: {metrics_url}\")\n",
    "            print(f\"  - Status: {response.status_code}\")\n",
    "            print(f\"  - Metrics found: {metrics_count} lines\")\n",
    "        else:\n",
    "            print(f\"⚠ App /metrics endpoint returned status: {response.status_code}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"⚠ STUB: App /metrics endpoint not accessible\")\n",
    "        print(\"  - Service may not be running on localhost:8000\")\n",
    "        print(\"  - To validate: Start your RAG app, then check http://localhost:8000/metrics\")\n",
    "        print(\"  - Expected: Prometheus-format metrics (text/plain)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error checking metrics: {e}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Check Prometheus targets (offline-friendly)\n",
    "    try:\n",
    "        response = requests.get(prometheus_url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✓ Prometheus targets page: ACCESSIBLE\")\n",
    "            print(f\"  - URL: {prometheus_url}\")\n",
    "            print(f\"  - Check manually for target state: UP\")\n",
    "        else:\n",
    "            print(f\"⚠ Prometheus returned status: {response.status_code}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"⚠ STUB: Prometheus not accessible\")\n",
    "        print(\"  - Service may not be running on localhost:9090\")\n",
    "        print(\"  - To validate: Start Prometheus, then check http://localhost:9090/targets\")\n",
    "        print(\"  - Expected: Your app listed as 'UP' with last scrape <30s ago\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error checking Prometheus: {e}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run the check\n",
    "check_metrics_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Validation Check 2 - Grafana Dashboard Panels\n",
    "\n",
    "### ✓ Check: Grafana Showing Key Metrics\n",
    "\n",
    "**What to verify:**\n",
    "- Dashboard displays: p95 latency, error rate, cache hit rate, cost accumulation\n",
    "- All panels show data for last 30 minutes\n",
    "- Graphs are not empty\n",
    "\n",
    "**Why this matters for M2.4:**\n",
    "- Will measure retry effectiveness (error rate 2% → <0.1%)\n",
    "- Track latency impact of retries (+50-200ms per retry)\n",
    "- Monitor circuit breaker state transitions\n",
    "- Observe degradation patterns in real-time\n",
    "\n",
    "**Success criteria:**\n",
    "- All 4 key panels populated with data\n",
    "- Time range: last 30 minutes minimum\n",
    "- PromQL queries returning results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Dashboard Spec:** Creates a local JSON file with 4 Grafana panel definitions (p95 latency, error rate, cache hit rate, cost). This runs offline and produces `grafana_panels_spec.json` that you can import into Grafana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_grafana_panel_spec():\n",
    "    \"\"\"Create JSON specification for required Grafana panels\"\"\"\n",
    "    \n",
    "    grafana_panels = {\n",
    "        \"dashboard\": {\n",
    "            \"title\": \"RAG Pipeline Observability - M2.3\",\n",
    "            \"tags\": [\"rag\", \"m2.3\", \"observability\"],\n",
    "            \"timezone\": \"browser\",\n",
    "            \"panels\": [\n",
    "                {\n",
    "                    \"id\": 1,\n",
    "                    \"title\": \"p95 Latency\",\n",
    "                    \"type\": \"graph\",\n",
    "                    \"targets\": [\n",
    "                        {\n",
    "                            \"expr\": \"histogram_quantile(0.95, rate(rag_query_duration_seconds_bucket[5m]))\",\n",
    "                            \"legendFormat\": \"p95 latency\",\n",
    "                            \"refId\": \"A\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"yaxes\": [\n",
    "                        {\"format\": \"s\", \"label\": \"Duration\"}\n",
    "                    ],\n",
    "                    \"alert\": {\n",
    "                        \"name\": \"High p95 Latency\",\n",
    "                        \"conditions\": [\n",
    "                            {\n",
    "                                \"evaluator\": {\"params\": [0.5], \"type\": \"gt\"},\n",
    "                                \"query\": {\"params\": [\"A\", \"5m\", \"now\"]},\n",
    "                                \"type\": \"query\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"message\": \"p95 latency exceeded 500ms\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 2,\n",
    "                    \"title\": \"Error Rate (%)\",\n",
    "                    \"type\": \"graph\",\n",
    "                    \"targets\": [\n",
    "                        {\n",
    "                            \"expr\": \"rate(rag_errors_total[5m]) / rate(rag_requests_total[5m]) * 100\",\n",
    "                            \"legendFormat\": \"Error rate %\",\n",
    "                            \"refId\": \"A\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"yaxes\": [\n",
    "                        {\"format\": \"percent\", \"label\": \"Error Rate\"}\n",
    "                    ],\n",
    "                    \"alert\": {\n",
    "                        \"name\": \"High Error Rate\",\n",
    "                        \"conditions\": [\n",
    "                            {\n",
    "                                \"evaluator\": {\"params\": [1.0], \"type\": \"gt\"},\n",
    "                                \"query\": {\"params\": [\"A\", \"5m\", \"now\"]},\n",
    "                                \"type\": \"query\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"message\": \"Error rate exceeded 1% for 5 minutes\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 3,\n",
    "                    \"title\": \"Cache Hit Rate (%)\",\n",
    "                    \"type\": \"graph\",\n",
    "                    \"targets\": [\n",
    "                        {\n",
    "                            \"expr\": \"rate(rag_cache_hits_total[5m]) / rate(rag_cache_requests_total[5m]) * 100\",\n",
    "                            \"legendFormat\": \"Cache hit rate %\",\n",
    "                            \"refId\": \"A\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"yaxes\": [\n",
    "                        {\"format\": \"percent\", \"label\": \"Hit Rate\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"id\": 4,\n",
    "                    \"title\": \"Cost Accumulation\",\n",
    "                    \"type\": \"graph\",\n",
    "                    \"targets\": [\n",
    "                        {\n",
    "                            \"expr\": \"sum(increase(rag_cost_usd_total[1h]))\",\n",
    "                            \"legendFormat\": \"Hourly cost (USD)\",\n",
    "                            \"refId\": \"A\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"yaxes\": [\n",
    "                        {\"format\": \"currencyUSD\", \"label\": \"Cost\"}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"refresh\": \"15s\",\n",
    "            \"time\": {\n",
    "                \"from\": \"now-30m\",\n",
    "                \"to\": \"now\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Write to local file (no external calls)\n",
    "    spec_file = \"grafana_panels_spec.json\"\n",
    "    with open(spec_file, 'w') as f:\n",
    "        json.dump(grafana_panels, f, indent=2)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CHECK 2: Grafana Dashboard Panels\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"✓ Panel specification created: {spec_file}\")\n",
    "    print()\n",
    "    print(\"Required Panels (4):\")\n",
    "    for panel in grafana_panels[\"dashboard\"][\"panels\"]:\n",
    "        print(f\"  {panel['id']}. {panel['title']}\")\n",
    "    print()\n",
    "    print(f\"Specification saved to: {spec_file}\")\n",
    "    print(\"Import this JSON into Grafana to create the dashboard\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    return grafana_panels\n",
    "\n",
    "# Create the spec\n",
    "panels = create_grafana_panel_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Validation Check 3 - Alert Rules Configuration\n",
    "\n",
    "### ✓ Check: Alert Rules Configured and Tested\n",
    "\n",
    "**What to verify:**\n",
    "- Alert rules exist for critical conditions\n",
    "- Test alert can be triggered\n",
    "- Slack/email notifications arrive within 2 minutes\n",
    "- Alert includes metric value and threshold\n",
    "\n",
    "**Why this matters for M2.4:**\n",
    "- Will configure circuit breaker state change alerts (OPEN → HALF-OPEN → CLOSED)\n",
    "- Need to know when system is degraded and when it recovers\n",
    "- Without working alerts, won't know if error handling is functioning\n",
    "- M2.4 adds new alert types (retry exhaustion, circuit breaker trips, degradation mode)\n",
    "\n",
    "**Success criteria:**\n",
    "- 3+ alert rules configured (latency, error rate, rate limit)\n",
    "- Test alert successfully triggered and received\n",
    "- Alert Manager properly configured\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Alert Rules:** Creates a local YAML file with 4 Prometheus alert rules (3 for M2.3, 1 preview for M2.4 circuit breakers). Runs offline and produces `prometheus_alert_rules.yml` for Prometheus configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def create_alert_rules_stub():\n",
    "    \"\"\"Create YAML stub for Prometheus alert rules\"\"\"\n",
    "    \n",
    "    alert_rules = {\n",
    "        \"groups\": [\n",
    "            {\n",
    "                \"name\": \"rag_pipeline_alerts\",\n",
    "                \"interval\": \"30s\",\n",
    "                \"rules\": [\n",
    "                    {\n",
    "                        \"alert\": \"HighP95Latency\",\n",
    "                        \"expr\": \"histogram_quantile(0.95, rate(rag_query_duration_seconds_bucket[5m])) > 0.5\",\n",
    "                        \"for\": \"5m\",\n",
    "                        \"labels\": {\n",
    "                            \"severity\": \"warning\",\n",
    "                            \"component\": \"rag_pipeline\"\n",
    "                        },\n",
    "                        \"annotations\": {\n",
    "                            \"summary\": \"High p95 latency detected\",\n",
    "                            \"description\": \"p95 latency is {{ $value }}s (threshold: 500ms) for 5 minutes\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"alert\": \"HighErrorRate\",\n",
    "                        \"expr\": \"(rate(rag_errors_total[5m]) / rate(rag_requests_total[5m])) * 100 > 1.0\",\n",
    "                        \"for\": \"5m\",\n",
    "                        \"labels\": {\n",
    "                            \"severity\": \"critical\",\n",
    "                            \"component\": \"rag_pipeline\"\n",
    "                        },\n",
    "                        \"annotations\": {\n",
    "                            \"summary\": \"High error rate detected\",\n",
    "                            \"description\": \"Error rate is {{ $value }}% (threshold: 1%) for 5 minutes\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"alert\": \"LowRateLimitHeadroom\",\n",
    "                        \"expr\": \"rag_rate_limit_headroom_percent < 20\",\n",
    "                        \"for\": \"2m\",\n",
    "                        \"labels\": {\n",
    "                            \"severity\": \"warning\",\n",
    "                            \"component\": \"api_gateway\"\n",
    "                        },\n",
    "                        \"annotations\": {\n",
    "                            \"summary\": \"Rate limit headroom low\",\n",
    "                            \"description\": \"Rate limit headroom at {{ $value }}% (threshold: 20%)\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"alert\": \"CircuitBreakerOpen\",\n",
    "                        \"expr\": \"rag_circuit_breaker_state{state=\\\"open\\\"} == 1\",\n",
    "                        \"for\": \"1m\",\n",
    "                        \"labels\": {\n",
    "                            \"severity\": \"warning\",\n",
    "                            \"component\": \"resilience\",\n",
    "                            \"m2_4\": \"true\"\n",
    "                        },\n",
    "                        \"annotations\": {\n",
    "                            \"summary\": \"Circuit breaker opened\",\n",
    "                            \"description\": \"Circuit breaker for {{ $labels.service }} is OPEN - service degraded\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Write YAML to file (no external calls)\n",
    "    rules_file = \"prometheus_alert_rules.yml\"\n",
    "    with open(rules_file, 'w') as f:\n",
    "        yaml.dump(alert_rules, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CHECK 3: Alert Rules Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"✓ Alert rules YAML created: {rules_file}\")\n",
    "    print()\n",
    "    print(\"Configured Alert Rules:\")\n",
    "    for rule in alert_rules[\"groups\"][0][\"rules\"]:\n",
    "        print(f\"  • {rule['alert']} (severity: {rule['labels']['severity']})\")\n",
    "    print()\n",
    "    print(f\"YAML saved to: {rules_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    return alert_rules\n",
    "\n",
    "# Create alert rules\n",
    "rules = create_alert_rules_stub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Validation Check 4 - Structured Logging with Correlation IDs\n",
    "\n",
    "### ✓ Check: Correlation IDs in Structured Logs\n",
    "\n",
    "**What to verify:**\n",
    "- Logs are in JSON format\n",
    "- Every log entry includes `correlation_id` or `request_id`\n",
    "- Can trace full request lifecycle using correlation ID\n",
    "- Log entries: query received → embedding → vector search → LLM call → response\n",
    "\n",
    "**Why this matters for M2.4:**\n",
    "- M2.4 error handling produces MORE logs (retry attempts, circuit breaker state changes, fallback triggers)\n",
    "- Without correlation IDs: thousands of log lines with no way to trace a single failing request\n",
    "- Retry debugging requires tracing: initial attempt → retry 1 → retry 2 → success/failure\n",
    "- Circuit breaker state changes need correlation to specific requests that triggered the change\n",
    "\n",
    "**Success criteria:**\n",
    "- Logs in JSON format\n",
    "- `correlation_id` field present in all log entries\n",
    "- Can grep logs by correlation_id to see full request trace\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate Log Structure:** Demonstrates proper structured logging with correlation IDs by generating sample log entries. Shows a complete request lifecycle trace and validates that each entry contains the required `correlation_id` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "def validate_correlation_id_in_logs():\n",
    "    \"\"\"Validate that logs include correlation_id for request tracing\"\"\"\n",
    "    \n",
    "    # Sample log entries demonstrating proper structured logging (no external calls)\n",
    "    sample_correlation_id = str(uuid.uuid4())[:8]\n",
    "    \n",
    "    sample_logs = [\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"Query received\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"query\": \"What is RAG?\",\n",
    "            \"user_id\": \"user_123\"\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"Embedding generated\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"embedding_model\": \"text-embedding-ada-002\",\n",
    "            \"latency_ms\": 45\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"Vector search completed\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"results_count\": 5,\n",
    "            \"search_latency_ms\": 12\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"LLM call completed\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"tokens\": 450,\n",
    "            \"latency_ms\": 1200\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"Response returned\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"total_latency_ms\": 1257,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # M2.4 preview: retry logs with correlation\n",
    "    sample_logs_m24 = [\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"WARNING\",\n",
    "            \"message\": \"LLM call failed, retrying\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"error\": \"RateLimitError\",\n",
    "            \"retry_attempt\": 1,\n",
    "            \"backoff_ms\": 1000\n",
    "        },\n",
    "        {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"level\": \"INFO\",\n",
    "            \"message\": \"Retry successful\",\n",
    "            \"correlation_id\": sample_correlation_id,\n",
    "            \"retry_attempt\": 1,\n",
    "            \"final_status\": \"success\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CHECK 4: Structured Logging with Correlation IDs\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(f\"✓ Sample correlation_id: {sample_correlation_id}\")\n",
    "    print()\n",
    "    print(\"Example: Complete Request Trace (5 log entries)\")\n",
    "    for i, log in enumerate(sample_logs, 1):\n",
    "        print(f\"  {i}. {log['message']}\")\n",
    "    print()\n",
    "    \n",
    "    # Validate structure\n",
    "    all_have_correlation = all('correlation_id' in log for log in sample_logs)\n",
    "    print(\"Validation Results:\")\n",
    "    if all_have_correlation:\n",
    "        print(\"  ✓ All log entries contain 'correlation_id'\")\n",
    "    else:\n",
    "        print(\"  ✗ MISSING: Some logs lack 'correlation_id'\")\n",
    "    print(f\"  ✓ All logs are valid JSON\")\n",
    "    print(f\"  ✓ Request lifecycle traceable by correlation_id\")\n",
    "    print()\n",
    "    \n",
    "    # M2.4 Preview\n",
    "    print(\"M2.4 PREVIEW: Retry Logs with Correlation\")\n",
    "    for log in sample_logs_m24:\n",
    "        print(f\"  • {log['message']} (attempt: {log.get('retry_attempt', 'N/A')})\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    return sample_logs\n",
    "\n",
    "# Run validation\n",
    "logs = validate_correlation_id_in_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: M2.4 Call-Forward - Self-Healing Capabilities\n",
    "\n",
    "### What You'll Learn in M2.4: Error Handling & Reliability\n",
    "\n",
    "M2.4 teaches you the four resilience patterns that make production RAG systems bulletproof.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Retry Logic with Exponential Backoff\n",
    "\n",
    "**What it does:**\n",
    "- Automatically recover from transient API failures\n",
    "- Handle rate limits, timeouts, network glitches\n",
    "- Exponential backoff prevents overwhelming failing services\n",
    "\n",
    "**Trade-offs:**\n",
    "- Adds retry infrastructure complexity\n",
    "- Increases latency: +50-200ms per retry attempt\n",
    "- Must tune max retries (too many = wasted time, too few = missed recoveries)\n",
    "\n",
    "**Example transformation:**\n",
    "- **Before:** OpenAI timeout → user sees error → lost query\n",
    "- **After:** OpenAI timeout → retry with backoff → success on retry 2 → user gets answer (slower, but successful)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Circuit Breaker Pattern\n",
    "\n",
    "**What it does:**\n",
    "- Prevent cascading failures when dependencies are down\n",
    "- Stop hammering failing services, fail fast instead\n",
    "- Automatic recovery detection (half-open → closed states)\n",
    "\n",
    "**Trade-offs:**\n",
    "- Adds state machine complexity\n",
    "- 5-15ms per-request overhead for state checking\n",
    "- Risk of false positives (blocking healthy services after transient issues)\n",
    "\n",
    "**Example:**\n",
    "- Vector DB goes down for 30 seconds\n",
    "- Circuit breaker opens after 5 failures\n",
    "- New requests fail fast (no wasted retries)\n",
    "- Circuit breaker periodically tests recovery\n",
    "- Auto-closes when service returns\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Graceful Degradation Strategies\n",
    "\n",
    "**What it does:**\n",
    "- Continue serving *some* functionality when full features unavailable\n",
    "- Return cached results when vector DB is down\n",
    "- Provide simpler responses when LLM is rate-limited\n",
    "\n",
    "**Trade-offs:**\n",
    "- Requires fallback logic (20-30% more code)\n",
    "- Must maintain alternate code paths\n",
    "- Response quality may drop during degradation\n",
    "\n",
    "**Example fallback chain:**\n",
    "1. Full RAG (vector search + LLM): quality score 0.85\n",
    "2. Cached results only: quality score 0.75\n",
    "3. Static FAQ responses: quality score 0.60\n",
    "4. Error message with retry suggestion: quality score 0.0\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Request Queue with Rate Limiting\n",
    "\n",
    "**What it does:**\n",
    "- Handle traffic spikes without crashing\n",
    "- Queue excess requests during temporary overload\n",
    "- Prevents API rate limit violations\n",
    "\n",
    "**Trade-offs:**\n",
    "- Requires memory for queue (5KB per request)\n",
    "- Adds queueing delay under load\n",
    "- Must configure queue size limits (too small = rejected requests, too large = OOM)\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Impact After M2.4\n",
    "\n",
    "**Error rate transformation:**\n",
    "- **Current (M2.3):** 2% error rate (200 failures per 10,000 queries)\n",
    "- **Target (M2.4):** <0.1% error rate (<10 failures per 10,000 queries)\n",
    "\n",
    "**Why the improvement:**\n",
    "- Transient failures (80% of errors) automatically retried and succeed\n",
    "- Circuit breakers prevent repeated failures on broken dependencies\n",
    "- Graceful degradation keeps users productive during partial outages\n",
    "\n",
    "---\n",
    "\n",
    "### Honest Trade-offs Discussion\n",
    "\n",
    "M2.4 is NOT \"add resilience and everything is better.\" You'll learn:\n",
    "\n",
    "**When TO use error handling:**\n",
    "- Production systems with real users\n",
    "- APIs with known transient failures (rate limits, timeouts)\n",
    "- Dependencies with occasional downtime\n",
    "- Systems where availability > latency\n",
    "\n",
    "**When NOT to use:**\n",
    "- MVP phase (add complexity only when needed)\n",
    "- Internal tools with manual retry acceptable\n",
    "- Systems with zero-tolerance for latency increases\n",
    "- Single-user development environments\n",
    "\n",
    "---\n",
    "\n",
    "### Validation Time Investment\n",
    "\n",
    "**Before starting M2.4:**\n",
    "- Complete M2.3 validation checklist: 30-45 minutes\n",
    "- Review monitoring dashboards: 10 minutes\n",
    "- Optional: Screenshot current metrics for before/after comparison\n",
    "\n",
    "**M2.4 implementation time:**\n",
    "- Video duration: 32 minutes\n",
    "- Implementation: 2-3 hours\n",
    "- Testing and validation: 1 hour\n",
    "\n",
    "---\n",
    "\n",
    "### Module 2 Progress\n",
    "\n",
    "**You've completed 3 of 4 videos:**\n",
    "- ✓ M2.1: Caching for 60-80% cost reduction\n",
    "- ✓ M2.2: Prompt optimization for quality + cost\n",
    "- ✓ M2.3: Production monitoring and observability\n",
    "- **→ M2.4: Error handling and resilience** ← Next\n",
    "\n",
    "**After M2.4:**\n",
    "- Complete production RAG system: cost-efficient, observable, resilient\n",
    "- Module 3: Deploy to cloud (AWS/GCP/Azure)\n",
    "- Module 4: Advanced retrieval techniques\n",
    "\n",
    "---\n",
    "\n",
    "### Ready for M2.4?\n",
    "\n",
    "**Pre-flight checklist:**\n",
    "- [ ] All 4 M2.3 validation checks passing\n",
    "- [ ] Prometheus + Grafana accessible\n",
    "- [ ] Alert rules tested and working\n",
    "- [ ] Logs include correlation IDs\n",
    "- [ ] 15-minute break taken (M2.4 is dense!)\n",
    "\n",
    "**When ready, proceed to M2.4 video: Error Handling & Reliability**\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook complete!** Run all cells to validate your M2.3 readiness for M2.4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
