{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge M2.4 â†’ M3.1: Deployment-Gap Validation Baseline\n",
    "\n",
    "---\n",
    "\n",
    "## Run Locally (Windows)\n",
    "\n",
    "```powershell\n",
    "# From repository root\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "**What shifts:** You've completed Module 2 with an optimized, monitored, resilient RAG system running locally. But it's still on localhost:8000â€”inaccessible to real users. Module 3 bridges this gap by deploying your system to production with public HTTPS access, automated health checks, and one-command deployments.\n",
    "\n",
    "**Why it matters:** Without deployment, your production-ready code has no production impact. This baseline captures your current manual deployment process, recovery times, and risks so you can measure the improvement Module 3 delivers (80% faster deployments, 90% faster recovery, $350-550/month time savings).\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts Covered\n",
    "\n",
    "**New in this bridge:**\n",
    "- **Deployment baseline:** Documenting manual steps and time costs\n",
    "- **MTTR (Mean Time To Recovery):** Detection â†’ Diagnosis â†’ Fix â†’ Verification\n",
    "- **Risk assessment:** Likelihood Ã— Impact matrix for deployment failures\n",
    "- **Containerization preview:** Dockerfile and docker-compose concepts for M3.1\n",
    "\n",
    "---\n",
    "\n",
    "## After Completing\n",
    "\n",
    "You will have:\n",
    "- âœ… Documented your current deployment process in `deployment_process.json`\n",
    "- âœ… Measured your MTTR baseline (typically 30-120 minutes) in `mttr_baseline.json`\n",
    "- âœ… Identified your top 3 deployment risks in `deployment_risks.json`\n",
    "- âœ… Clear goals for Module 3 (one-command deploy, <5 min MTTR, public HTTPS)\n",
    "- âœ… Understanding of Docker containerization concepts for M3.1\n",
    "\n",
    "---\n",
    "\n",
    "## Context in Track\n",
    "\n",
    "**Bridge:** M2.4 Error Handling & Reliability â†’ M3.1 Containerization with Docker  \n",
    "**Module progress:** Module 2 Complete (Cost Optimization & Monitoring) â†’ Module 3 (Production Deployment)  \n",
    "**Course progress:** 50% complete (Modules 1-2 done, Modules 3-4 ahead)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Module 2 Recap - What We Shipped\n",
    "\n",
    "### âœ… M2.1: Caching Strategies for Cost Reduction\n",
    "- **Shipped:** 3-layer semantic cache cutting costs 30-70%\n",
    "- **Shipped:** TTL-based cache invalidation preventing stale data\n",
    "- **Shipped:** Cache hit rate measurement and optimization\n",
    "- **Trade-off understood:** Freshness vs cost\n",
    "\n",
    "### âœ… M2.2: Prompt Optimization & Model Selection\n",
    "- **Shipped:** Prompt size reduction by 40-60% through structured formatting\n",
    "- **Shipped:** Intelligent routing (GPT-3.5 vs GPT-4) saving 30-50% on API costs\n",
    "- **Shipped:** Quality vs cost measurement framework\n",
    "- **Trade-off understood:** Token optimization can degrade answer quality\n",
    "\n",
    "### âœ… M2.3: Production Monitoring Dashboard\n",
    "- **Shipped:** Prometheus + Grafana for metrics collection and visualization\n",
    "- **Shipped:** Structured logging with trace IDs for debugging\n",
    "- **Shipped:** 8 critical alerts (errors, latency, cost, cache performance)\n",
    "- **Shipped:** Real-time system health dashboards\n",
    "\n",
    "### âœ… M2.4: Error Handling & Reliability\n",
    "- **Shipped:** Retry logic with exponential backoff + jitter\n",
    "- **Shipped:** Circuit breaker isolating Pinecone failures\n",
    "- **Shipped:** 3-level graceful degradation (FULL/DEGRADED/MINIMAL)\n",
    "- **Shipped:** 5 failure scenario tests with validated recovery\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Portfolio-Worthy Achievement\n",
    "\n",
    "**What you built:**\n",
    "- Cost-optimized RAG system running at 40-70% lower expense\n",
    "- Full observability with metrics, logs, and alerts\n",
    "- Resilience patterns handling 95%+ of errors automatically\n",
    "- Production-grade monitoring identifying issues before users notice\n",
    "\n",
    "**Typical Results:**\n",
    "- **Before M2:** $300-600/month API costs, 5-10% error rate, 4-6 hours/week debugging\n",
    "- **After M2:** $90-180/month API costs (70% reduction), 95% error recovery, 2-3 hours/week saved\n",
    "- **ROI:** $210-420/month saved Ã— 12 = $2,520-5,040/year\n",
    "\n",
    "---\n",
    "\n",
    "**SAVED_SECTION: 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Current Deployment Process - Manual Steps Baseline\n",
    "\n",
    "**The Deployment Gap:** Your RAG system is optimized, monitored, and resilient... but it's running on localhost:8000.\n",
    "\n",
    "### Problems with Current State:\n",
    "- âŒ Can't serve real users from your laptop\n",
    "- âŒ No public URL accessible from anywhere\n",
    "- âŒ No HTTPS with valid SSL certificate\n",
    "- âŒ No automatic restarts if process crashes\n",
    "- âŒ No environment-based configuration (dev vs prod)\n",
    "- âŒ System disappears when laptop closes or internet goes down\n",
    "\n",
    "### Cost of Manual Deployment:\n",
    "- **Time cost:** 30-60 minutes per deployment Ã— 5 deployments/week = 2.5-5 hours/week\n",
    "- **Risk cost:** 2 hour recovery time Ã— 3 incidents/month Ã— 500 users = 3,000 user-hours of downtime/month\n",
    "- **Opportunity cost:** 10-15 hours/month on operational toil instead of building features\n",
    "- **Total:** $500-750/month in lost productivity at $50/hour opportunity cost\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Code Cell: Capture Deployment Process\n",
    "\n",
    "Define your current manual deployment steps as a Python dictionary and save to `deployment_process.json`. Edit the template with your actual steps (8-12 typical), time estimates, and deployment frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Template: Fill in your actual deployment steps\n",
    "deployment_process = {\n",
    "    \"captured_at\": datetime.now().isoformat(),\n",
    "    \"current_manual_steps\": [\n",
    "        {\"step\": 1, \"action\": \"Check .env file for API keys and configuration\", \"estimated_time_minutes\": 2},\n",
    "        {\"step\": 2, \"action\": \"Start Redis cache server locally\", \"estimated_time_minutes\": 1},\n",
    "        {\"step\": 3, \"action\": \"Start ChromaDB vector database\", \"estimated_time_minutes\": 2},\n",
    "        {\"step\": 4, \"action\": \"Start Prometheus for metrics collection\", \"estimated_time_minutes\": 1},\n",
    "        {\"step\": 5, \"action\": \"Start Grafana for dashboard visualization\", \"estimated_time_minutes\": 1},\n",
    "        {\"step\": 6, \"action\": \"Run database migrations if schema changed\", \"estimated_time_minutes\": 3},\n",
    "        {\"step\": 7, \"action\": \"Start FastAPI application server\", \"estimated_time_minutes\": 2},\n",
    "        {\"step\": 8, \"action\": \"Check logs for startup errors\", \"estimated_time_minutes\": 3},\n",
    "        {\"step\": 9, \"action\": \"Test health endpoint (curl localhost:8000/health)\", \"estimated_time_minutes\": 1},\n",
    "        {\"step\": 10, \"action\": \"Test RAG query endpoint with sample query\", \"estimated_time_minutes\": 2},\n",
    "        {\"step\": 11, \"action\": \"Check Grafana dashboards for metric collection\", \"estimated_time_minutes\": 2},\n",
    "        {\"step\": 12, \"action\": \"Monitor initial requests for errors\", \"estimated_time_minutes\": 5}\n",
    "    ],\n",
    "    \"total_estimated_time_minutes\": 25,\n",
    "    \"deployment_frequency_per_week\": 5,\n",
    "    \"weekly_time_cost_hours\": 2.1\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"deployment_process.json\", \"w\") as f:\n",
    "    json.dump(deployment_process, f, indent=2)\n",
    "\n",
    "print(\"âœ… Deployment process captured!\")\n",
    "print(f\"ðŸ“Š Total manual steps: {len(deployment_process['current_manual_steps'])}\")\n",
    "print(f\"â±ï¸  Estimated time per deployment: {deployment_process['total_estimated_time_minutes']} minutes\")\n",
    "print(f\"ðŸ“… Weekly time cost: {deployment_process['weekly_time_cost_hours']} hours\")\n",
    "print(\"\\nðŸ’¡ Edit the steps above to match YOUR actual deployment process, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**SAVED_SECTION: 2** - Current deployment process captured to `deployment_process.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: MTTR Baseline - Mean Time To Recovery\n",
    "\n",
    "**Purpose:** Measure how long it takes to detect and recover from a production incident in your current setup.\n",
    "\n",
    "### What is MTTR?\n",
    "\n",
    "**Mean Time To Recovery (MTTR)** = Time from failure occurrence â†’ Service fully restored\n",
    "\n",
    "**Formula:** MTTR = Detection Time + Diagnosis Time + Fix Time + Verification Time\n",
    "\n",
    "---\n",
    "\n",
    "### Why MTTR Matters:\n",
    "\n",
    "**Production incident scenario:**\n",
    "- Your RAG system crashes at 2 AM\n",
    "- Without automated monitoring, you don't know until users complain at 9 AM\n",
    "- **Detection time:** 7 hours\n",
    "- You investigate logs manually: **Diagnosis time:** 30 minutes\n",
    "- You restart services and redeploy: **Fix time:** 15 minutes\n",
    "- You verify with test queries: **Verification time:** 10 minutes\n",
    "- **Total MTTR:** 7 hours 55 minutes\n",
    "\n",
    "**Impact:** 500 users Ã— 7.9 hours = 3,950 user-hours of downtime from ONE incident\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Code Cell: Record MTTR Baseline\n",
    "\n",
    "Capture your MTTR by either simulating a failure (kill a process, time your recovery) or estimating from past incidents. Edit the four time components (detection, diagnosis, fix, verification) with your actual measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Record your MTTR measurements here\n",
    "# Edit these values based on your actual or estimated times\n",
    "mttr_baseline = {\n",
    "    \"captured_at\": datetime.now().isoformat(),\n",
    "    \"simulation_type\": \"Manual entry (update this: 'Actual simulation' or 'Estimated from past incidents')\",\n",
    "    \"failure_scenario\": \"FastAPI process crash (update with your actual scenario)\",\n",
    "    \n",
    "    # MTTR Components (in minutes)\n",
    "    \"detection_time_minutes\": 30,  # How long until you noticed the failure?\n",
    "    \"diagnosis_time_minutes\": 15,  # How long to identify the root cause?\n",
    "    \"fix_time_minutes\": 10,        # How long to fix and redeploy?\n",
    "    \"verification_time_minutes\": 5, # How long to verify recovery?\n",
    "    \n",
    "    # Calculated totals\n",
    "    \"total_mttr_minutes\": 60,\n",
    "    \"total_mttr_hours\": 1.0,\n",
    "    \n",
    "    # Context\n",
    "    \"detection_method\": \"Manual check (update: 'Alert', 'User complaint', 'Manual check', 'Scheduled health check')\",\n",
    "    \"monitoring_available\": True,  # Do you have Prometheus/Grafana monitoring?\n",
    "    \"alerts_configured\": False,    # Do you have alerts for failures?\n",
    "    \"automatic_recovery\": False,   # Is there any automatic restart mechanism?\n",
    "    \n",
    "    # Impact calculation\n",
    "    \"estimated_users_affected\": 100,\n",
    "    \"user_hours_lost\": 100,  # users Ã— MTTR hours\n",
    "    \"incidents_per_month\": 3,\n",
    "    \"monthly_downtime_hours\": 3.0,\n",
    "    \"monthly_user_hours_lost\": 300\n",
    "}\n",
    "\n",
    "# Calculate totals\n",
    "mttr_baseline[\"total_mttr_minutes\"] = (\n",
    "    mttr_baseline[\"detection_time_minutes\"] +\n",
    "    mttr_baseline[\"diagnosis_time_minutes\"] +\n",
    "    mttr_baseline[\"fix_time_minutes\"] +\n",
    "    mttr_baseline[\"verification_time_minutes\"]\n",
    ")\n",
    "mttr_baseline[\"total_mttr_hours\"] = round(mttr_baseline[\"total_mttr_minutes\"] / 60, 2)\n",
    "mttr_baseline[\"user_hours_lost\"] = mttr_baseline[\"estimated_users_affected\"] * mttr_baseline[\"total_mttr_hours\"]\n",
    "mttr_baseline[\"monthly_downtime_hours\"] = mttr_baseline[\"total_mttr_hours\"] * mttr_baseline[\"incidents_per_month\"]\n",
    "mttr_baseline[\"monthly_user_hours_lost\"] = mttr_baseline[\"user_hours_lost\"] * mttr_baseline[\"incidents_per_month\"]\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"mttr_baseline.json\", \"w\") as f:\n",
    "    json.dump(mttr_baseline, f, indent=2)\n",
    "\n",
    "print(\"âœ… MTTR baseline captured!\")\n",
    "print(f\"\\nðŸ“Š MTTR Breakdown:\")\n",
    "print(f\"  ðŸ” Detection: {mttr_baseline['detection_time_minutes']} min\")\n",
    "print(f\"  ðŸ”¬ Diagnosis: {mttr_baseline['diagnosis_time_minutes']} min\")\n",
    "print(f\"  ðŸ”§ Fix: {mttr_baseline['fix_time_minutes']} min\")\n",
    "print(f\"  âœ“ Verification: {mttr_baseline['verification_time_minutes']} min\")\n",
    "print(f\"  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(f\"  â±ï¸  Total MTTR: {mttr_baseline['total_mttr_minutes']} min ({mttr_baseline['total_mttr_hours']} hours)\")\n",
    "print(f\"\\nðŸŽ¯ Module 3 Goal: Reduce MTTR to <5 minutes with automated health checks and restarts\")\n",
    "print(\"\\nðŸ’¡ Edit the values above to match YOUR actual measurements, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**SAVED_SECTION: 3** - MTTR baseline captured to `mttr_baseline.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Top 3 Deployment Risks\n",
    "\n",
    "**Purpose:** Identify the biggest risks to successful deployment and plan mitigation strategies.\n",
    "\n",
    "### Common Deployment Risk Categories:\n",
    "\n",
    "1. **Configuration Risks:** Missing environment variables, incorrect API keys, database connection strings\n",
    "2. **Dependency Risks:** Version conflicts, missing packages, incompatible system libraries\n",
    "3. **Infrastructure Risks:** Insufficient memory/CPU, network connectivity, port conflicts\n",
    "4. **Data Risks:** Missing vector database data, cache not initialized, migration failures\n",
    "5. **Security Risks:** Exposed secrets, unsecured endpoints, CORS misconfiguration\n",
    "6. **Monitoring Gaps:** No health checks, missing metrics, silent failures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Code Cell: Document Deployment Risks\n",
    "\n",
    "Rank your top 3 deployment risks by likelihood Ã— impact. Edit the template with specific risks for your system (not generic categories). Save to `deployment_risks.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Document your top 3 deployment risks\n",
    "# Edit these based on YOUR system's specific risks\n",
    "deployment_risks = {\n",
    "    \"captured_at\": datetime.now().isoformat(),\n",
    "    \"risks\": [\n",
    "        {\n",
    "            \"rank\": 1,\n",
    "            \"title\": \"Missing or incorrect environment variables in production\",\n",
    "            \"category\": \"Configuration\",\n",
    "            \"description\": \"API keys, database URLs, or service credentials not properly configured in cloud environment\",\n",
    "            \"likelihood\": \"High\",  # High/Medium/Low\n",
    "            \"impact\": \"Critical\",  # Critical/High/Medium/Low\n",
    "            \"current_mitigation\": \"None - manual .env file management\",\n",
    "            \"m3_mitigation\": \"Environment variable validation at startup + .env.example template + Railway/Render secrets management\"\n",
    "        },\n",
    "        {\n",
    "            \"rank\": 2,\n",
    "            \"title\": \"Vector database (Chroma/Pinecone) connection failure in production\",\n",
    "            \"category\": \"Infrastructure\",\n",
    "            \"description\": \"Database not accessible from cloud environment due to network restrictions or missing data initialization\",\n",
    "            \"likelihood\": \"Medium\",\n",
    "            \"impact\": \"Critical\",\n",
    "            \"current_mitigation\": \"Circuit breaker pattern implemented in M2.4\",\n",
    "            \"m3_mitigation\": \"Docker container networking + health checks + persistent volume mounting for ChromaDB\"\n",
    "        },\n",
    "        {\n",
    "            \"rank\": 3,\n",
    "            \"title\": \"Insufficient memory causing container restarts under load\",\n",
    "            \"category\": \"Infrastructure\",\n",
    "            \"description\": \"RAG system with embedding models + cache + vector DB requires significant memory (2-4GB). Cloud free tiers may be insufficient.\",\n",
    "            \"likelihood\": \"Medium\",\n",
    "            \"impact\": \"High\",\n",
    "            \"current_mitigation\": \"None - not tested under production load\",\n",
    "            \"m3_mitigation\": \"Load testing in M3.4 + right-sizing cloud instance + memory monitoring alerts\"\n",
    "        }\n",
    "    ],\n",
    "    \"risk_matrix\": {\n",
    "        \"critical_risks\": 1,\n",
    "        \"high_risks\": 1,\n",
    "        \"medium_risks\": 1,\n",
    "        \"low_risks\": 0\n",
    "    },\n",
    "    \"overall_deployment_readiness\": \"MEDIUM - Multiple high-impact risks identified, mitigations planned for M3\"\n",
    "}\n",
    "\n",
    "# Calculate risk counts\n",
    "critical = sum(1 for r in deployment_risks[\"risks\"] if r[\"likelihood\"] == \"High\" and r[\"impact\"] == \"Critical\")\n",
    "high = sum(1 for r in deployment_risks[\"risks\"] if (r[\"likelihood\"] == \"Medium\" and r[\"impact\"] in [\"Critical\", \"High\"]) or (r[\"likelihood\"] == \"High\" and r[\"impact\"] == \"High\"))\n",
    "medium = sum(1 for r in deployment_risks[\"risks\"] if r[\"likelihood\"] == \"Medium\" and r[\"impact\"] == \"Medium\")\n",
    "low = sum(1 for r in deployment_risks[\"risks\"] if r[\"likelihood\"] == \"Low\" or r[\"impact\"] == \"Low\")\n",
    "\n",
    "deployment_risks[\"risk_matrix\"] = {\n",
    "    \"critical_risks\": critical,\n",
    "    \"high_risks\": high,\n",
    "    \"medium_risks\": medium,\n",
    "    \"low_risks\": low\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"deployment_risks.json\", \"w\") as f:\n",
    "    json.dump(deployment_risks, f, indent=2)\n",
    "\n",
    "print(\"âœ… Deployment risks captured!\")\n",
    "print(f\"\\nðŸš¨ Top 3 Risks Identified:\\n\")\n",
    "for risk in deployment_risks[\"risks\"]:\n",
    "    print(f\"{risk['rank']}. {risk['title']}\")\n",
    "    print(f\"   ðŸ“ Category: {risk['category']}\")\n",
    "    print(f\"   ðŸ“Š Likelihood: {risk['likelihood']} | Impact: {risk['impact']}\")\n",
    "    print(f\"   ðŸ›¡ï¸  Current Mitigation: {risk['current_mitigation']}\")\n",
    "    print(f\"   ðŸŽ¯ M3 Mitigation: {risk['m3_mitigation']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"ðŸ“ˆ Risk Matrix:\")\n",
    "print(f\"   ðŸ”´ Critical: {deployment_risks['risk_matrix']['critical_risks']}\")\n",
    "print(f\"   ðŸŸ  High: {deployment_risks['risk_matrix']['high_risks']}\")\n",
    "print(f\"   ðŸŸ¡ Medium: {deployment_risks['risk_matrix']['medium_risks']}\")\n",
    "print(f\"   ðŸŸ¢ Low: {deployment_risks['risk_matrix']['low_risks']}\")\n",
    "print(f\"\\nðŸŽ¯ Overall Readiness: {deployment_risks['overall_deployment_readiness']}\")\n",
    "print(\"\\nðŸ’¡ Edit the risks above to match YOUR system's specific deployment risks, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**SAVED_SECTION: 4** - Deployment risks captured to `deployment_risks.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Module 3 Deployment Goals\n",
    "\n",
    "**Purpose:** Define clear, measurable goals for what Module 3 will achieve.\n",
    "\n",
    "### The Deployment Vision:\n",
    "\n",
    "**Current State (Post-M2):**\n",
    "- Optimized, monitored, resilient RAG system\n",
    "- Running on localhost:8000\n",
    "- 25+ minutes manual deployment\n",
    "- 60+ minute MTTR\n",
    "- High deployment risks\n",
    "\n",
    "**Target State (Post-M3):**\n",
    "- Same system, but accessible to the world\n",
    "- Public HTTPS URL\n",
    "- One-command deployment\n",
    "- <5 minute MTTR with automated health checks\n",
    "- Deployment risks mitigated\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Core Module 3 Goals\n",
    "\n",
    "#### 1. **One-Command Deployment** (M3.1 Containerization)\n",
    "- **Goal:** Package RAG system into Docker containers\n",
    "- **Success metric:** `docker-compose up` starts entire stack (API + Chroma + Redis + Prometheus + Grafana)\n",
    "- **Learning curve:** 4-6 hours (Docker fundamentals)\n",
    "- **Trade-off:** Adds deployment complexity, but provides portability\n",
    "\n",
    "#### 2. **Public HTTPS Access** (M3.2 Cloud Deployment)\n",
    "- **Goal:** Deploy to Railway or Render with automatic SSL\n",
    "- **Success metric:** Public URL accessible from anywhere\n",
    "- **Cost:** $5-50/month for cloud hosting\n",
    "- **Trade-off:** Monthly cost vs. 24/7 availability\n",
    "\n",
    "#### 3. **Automated Health Checks & Restarts** (M3.2 Cloud Deployment)\n",
    "- **Goal:** Cloud platform automatically restarts containers on failure\n",
    "- **Success metric:** MTTR reduces from 60+ minutes to <5 minutes\n",
    "- **Trade-off:** 10-20% performance overhead for health check endpoints\n",
    "\n",
    "#### 4. **Environment-Based Configuration** (M3.1 + M3.2)\n",
    "- **Goal:** Separate dev/prod environments with secrets management\n",
    "- **Success metric:** No hardcoded credentials, .env files not committed to Git\n",
    "- **Trade-off:** More configuration complexity\n",
    "\n",
    "#### 5. **Zero-Downtime Deployments** (M3.2 Cloud Deployment)\n",
    "- **Goal:** Update code without stopping service\n",
    "- **Success metric:** Rolling deployments with health checks\n",
    "- **Trade-off:** Requires blue-green deployment or canary releases (added complexity)\n",
    "\n",
    "#### 6. **Foundation for Horizontal Scaling** (M3.4 Load Testing)\n",
    "- **Goal:** Validate system under load, prepare for multi-instance scaling\n",
    "- **Success metric:** Handle 100-1000 requests/sec, identify bottlenecks\n",
    "- **Trade-off:** Scaling increases costs linearly\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š Expected Improvements (Post-M3)\n",
    "\n",
    "**Deployment Time:**\n",
    "- Before: 25 minutes manual\n",
    "- After: <5 minutes automated\n",
    "- Improvement: 80% time reduction\n",
    "\n",
    "**Mean Time To Recovery (MTTR):**\n",
    "- Before: 60 minutes\n",
    "- After: <5 minutes\n",
    "- Improvement: 90%+ MTTR reduction\n",
    "\n",
    "**Availability:**\n",
    "- Before: Limited to your laptop's uptime\n",
    "- After: 99%+ uptime with cloud hosting\n",
    "\n",
    "**Productivity:**\n",
    "- Before: 10-15 hours/month operational toil\n",
    "- After: 2-3 hours/month\n",
    "- Improvement: 75% time savings\n",
    "\n",
    "**Cost Impact:**\n",
    "- New cost: $5-50/month cloud hosting\n",
    "- Time saved: 8-12 hours/month Ã— $50/hour = $400-600/month\n",
    "- Net benefit: $350-550/month\n",
    "\n",
    "---\n",
    "\n",
    "**SAVED_SECTION: 5** - Module 3 goals defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Call-Forward - M3.1 Containerization Preview\n",
    "\n",
    "**Purpose:** Preview what you'll build in M3.1: Containerization with Docker\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ What is Containerization?\n",
    "\n",
    "**Docker** packages your application + all dependencies into a standardized unit (container) that runs identically anywhere.\n",
    "\n",
    "**Problem Docker solves:**\n",
    "- \"Works on my machine\" syndrome\n",
    "- Dependency conflicts between dev/prod environments\n",
    "- Complex multi-service deployments (API + Database + Cache + Monitoring)\n",
    "\n",
    "**How it works:**\n",
    "1. **Dockerfile** = Recipe for building your application container\n",
    "2. **docker-compose.yml** = Orchestration file defining all services\n",
    "3. **docker-compose up** = One command to start entire stack\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ M3.1 Preview: What You'll Build\n",
    "\n",
    "#### 1. **Dockerfile for FastAPI RAG Application**\n",
    "\n",
    "```dockerfile\n",
    "# Example preview - NOT final code\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "EXPOSE 8000\n",
    "HEALTHCHECK --interval=30s --timeout=3s \\\n",
    "  CMD curl -f http://localhost:8000/health || exit 1\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "#### 2. **docker-compose.yml for Multi-Service Orchestration**\n",
    "\n",
    "```yaml\n",
    "# Example preview - NOT final code\n",
    "version: '3.8'\n",
    "services:\n",
    "  api:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    depends_on:\n",
    "      - redis\n",
    "      - chroma\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "  chroma:\n",
    "    image: chromadb/chroma:latest\n",
    "    volumes:\n",
    "      - chroma_data:/chroma/chroma\n",
    "volumes:\n",
    "  redis_data:\n",
    "  chroma_data:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ One-Command Deployment\n",
    "\n",
    "**Before M3.1 (12 manual steps):**\n",
    "```bash\n",
    "redis-server &\n",
    "chroma run &\n",
    "prometheus --config.file=prometheus.yml &\n",
    "grafana-server &\n",
    "python -m uvicorn main:app --reload\n",
    "# ... check logs, test endpoints, monitor ...\n",
    "```\n",
    "\n",
    "**After M3.1 (1 command):**\n",
    "```bash\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“š M3.1 Learning Path\n",
    "\n",
    "**Duration:** 45-minute video + 2-3 hours hands-on practice  \n",
    "**Learning curve:** 4-6 hours total\n",
    "\n",
    "**Topics:**\n",
    "1. Docker fundamentals (images, containers, volumes, networks)\n",
    "2. Writing Dockerfile for FastAPI RAG application\n",
    "3. Creating docker-compose.yml for multi-service orchestration\n",
    "4. Environment variable management\n",
    "5. Health checks and restart policies\n",
    "6. Volume mounting for persistent data\n",
    "7. Local testing before cloud deployment\n",
    "\n",
    "**Trade-offs:**\n",
    "- Adds deployment complexity (need to learn Docker)\n",
    "- 10-20% performance overhead (containerization layer)\n",
    "- More configuration files to manage\n",
    "\n",
    "**Benefits:**\n",
    "- Portability: Runs identically on dev/prod\n",
    "- Consistency: \"Works on my machine\" eliminated\n",
    "- Foundation for cloud deployment in M3.2\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Readiness Check Before M3.1\n",
    "\n",
    "1. **Module 2 complete:** Cost optimization, monitoring, error handling shipped\n",
    "2. **Code committed to Git:** All changes pushed, .env excluded\n",
    "3. **Docker installed:** `docker --version` and `docker-compose --version` work\n",
    "4. **Baseline captured:** This notebook completed with all JSON files saved\n",
    "5. **Goals clear:** You know what M3 will achieve (see Section 5)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Next Steps\n",
    "\n",
    "1. **Complete this notebook:** Fill in all sections with YOUR actual data\n",
    "2. **Save baseline files:** Ensure JSON files are created\n",
    "3. **Commit to Git:** Track your pre-M3 state for comparison\n",
    "4. **Install Docker:** If not already installed\n",
    "5. **Start M3.1:** Containerization with Docker\n",
    "\n",
    "---\n",
    "\n",
    "**SAVED_SECTION: 6** - Call-forward to M3.1 complete\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Baseline Capture Complete!\n",
    "\n",
    "**Files created:**\n",
    "- `deployment_process.json` - Current manual steps\n",
    "- `mttr_baseline.json` - Mean time to recovery metrics\n",
    "- `deployment_risks.json` - Top 3 deployment risks\n",
    "\n",
    "**Next:** Start M3.1 Containerization with Docker when ready!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
