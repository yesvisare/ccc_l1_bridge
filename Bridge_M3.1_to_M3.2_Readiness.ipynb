{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arc_purpose",
   "metadata": {},
   "source": [
    "# Bridge M3.1 ‚Üí M3.2: Readiness Checklist\n",
    "\n",
    "## üéØ Purpose\n",
    "\n",
    "**What shifts:** You've containerized your application with Docker (M3.1). Now you need to verify that your local setup is production-ready before deploying to cloud platforms (M3.2).\n",
    "\n",
    "**Why it matters:** Cloud deployment failures often stem from issues that could be caught locally. Missing environment variables, leaked secrets in Git history, or unhealthy Docker containers will waste 30-90 minutes of remote debugging. This readiness checklist catches those issues in 5 minutes locally.\n",
    "\n",
    "**The gap:** Docker made your app portable, but you haven't verified it's cloud-ready. This bridge ensures your Dockerfile, environment configuration, and Git hygiene meet production standards before you push to Railway or Render."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc_concepts",
   "metadata": {},
   "source": [
    "## üìö Concepts Covered\n",
    "\n",
    "**Delta from M3.1:**\n",
    "- Pre-deployment validation patterns (health checks, configuration audits)\n",
    "- Secrets management best practices (.env.example pattern, Git history scanning)\n",
    "- Multi-environment configuration strategies (staging vs. production)\n",
    "- Offline-first notebook execution (graceful fallbacks for missing tools)\n",
    "\n",
    "**Not covered:** Actual cloud deployment (that's M3.2), CI/CD pipelines, or infrastructure-as-code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc_outcomes",
   "metadata": {},
   "source": [
    "## ‚úÖ After Completing\n",
    "\n",
    "You will be able to verify:\n",
    "- ‚úì Your Docker Compose stack starts successfully and all services are healthy\n",
    "- ‚úì All required environment variables are documented in .env.example with no secrets leaked\n",
    "- ‚úì Your Git repository has no sensitive files in history (.env, credentials.json, etc.)\n",
    "- ‚úì (Optional) You have multi-environment configuration experience with staging compose files\n",
    "- ‚úì Your project meets cloud platform requirements for Railway and Render deployment\n",
    "\n",
    "**Pass criteria:** All 3 required checks (Docker health, .env.example, Git secrets) must pass. The staging check is optional but recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc_context",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Context in Track\n",
    "\n",
    "**Module:** L1.M3 - Production Deployment  \n",
    "**Bridge Type:** Within-Module (M3.1 ‚Üí M3.2)  \n",
    "**Duration:** 30-45 minutes  \n",
    "**Previous:** M3.1 - Containerization with Docker (Dockerfile, docker-compose, volumes)  \n",
    "**Next:** M3.2 - Cloud Deployment (Railway/Render PaaS platforms)\n",
    "\n",
    "---\n",
    "\n",
    "### üíª Run Locally (Windows)\n",
    "\n",
    "```powershell\n",
    "# From your project root:\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "**Linux/Mac:**\n",
    "```bash\n",
    "export PYTHONPATH=\"$PWD\" && jupyter notebook\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recap",
   "metadata": {},
   "source": [
    "## Section 1: RECAP - What You Accomplished\n",
    "\n",
    "### Congratulations! You completed M3.1: Containerization with Docker\n",
    "\n",
    "Here's what you built:\n",
    "\n",
    "### ‚úì Complete Docker containerization of your RAG system\n",
    "- Created production-ready Dockerfile with optimized layer caching\n",
    "- Multi-stage builds for 40% faster rebuilds\n",
    "- Non-root user for security hardening\n",
    "\n",
    "### ‚úì Multi-service orchestration with docker-compose\n",
    "- Integrated RAG API, Redis cache, and vector database\n",
    "- Single orchestrated stack that starts with one command\n",
    "- Automatic networking management\n",
    "\n",
    "### ‚úì Data persistence strategy implemented\n",
    "- Volume mounts for document storage and embeddings\n",
    "- Data survives container restarts\n",
    "- Updates possible without rebuilding images\n",
    "\n",
    "### ‚úì Five common Docker failures debugged live\n",
    "- Port conflicts\n",
    "- Volume permission errors\n",
    "- Networking issues\n",
    "- Environment variable problems\n",
    "- Image build failures\n",
    "\n",
    "---\n",
    "\n",
    "**Key Achievement:** Your RAG system is now portable and runs identically on any machine with Docker installed. Your Dockerfile and docker-compose.yml are production artifacts - the foundation for cloud deployment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_header",
   "metadata": {},
   "source": [
    "## Section 2: CHECK - Docker Compose Health\n",
    "\n",
    "**Requirement:** Docker stack runs successfully with `docker-compose up`\n",
    "\n",
    "**Impact:** Failed local deployment means cloud deployment will also fail - wastes 30-60 minutes debugging remotely instead of locally\n",
    "\n",
    "**What to verify:**\n",
    "- Run `docker-compose up -d` and `docker-compose ps` shows all services healthy\n",
    "- All containers are in \"running\" state\n",
    "- No restart loops or exit codes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_intro",
   "metadata": {},
   "source": [
    "**What this check does:** Verifies that Docker and docker-compose are installed, that docker-compose.yml exists, and that all services start successfully. If Docker is unavailable, the check skips gracefully with a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_docker_compose_health():\n",
    "    \"\"\"Check if docker-compose services are healthy\"\"\"\n",
    "    print(\"üîç Checking Docker Compose Health...\\n\")\n",
    "    \n",
    "    # Check if docker-compose.yml exists\n",
    "    if not os.path.exists('docker-compose.yml'):\n",
    "        print(\"‚ö†Ô∏è  WARNING: docker-compose.yml not found in current directory\")\n",
    "        print(\"   This check will be skipped - ensure you have this file before cloud deployment\\n\")\n",
    "        return False\n",
    "    \n",
    "    # Offline-friendly: Skip if Docker not available\n",
    "    try:\n",
    "        result = subprocess.run(['docker', '--version'], \n",
    "                              capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Docker is not available on this system\")\n",
    "            print(\"   This check will be skipped - install Docker to verify locally\\n\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úì Docker detected: {result.stdout.strip()}\\n\")\n",
    "        \n",
    "        # Try to check docker-compose status\n",
    "        result = subprocess.run(['docker-compose', 'ps'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"Docker Compose Status:\")\n",
    "            print(result.stdout)\n",
    "            \n",
    "            if \"Up\" in result.stdout:\n",
    "                print(\"‚úÖ PASS: Docker containers are running\")\n",
    "                return True\n",
    "            elif result.stdout.strip() == \"\" or \"Name\" in result.stdout and len(result.stdout.split('\\n')) <= 2:\n",
    "                print(\"‚ö†Ô∏è  No containers currently running\")\n",
    "                print(\"   Run: docker-compose up -d\")\n",
    "                return False\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  WARNING: Some containers may have issues\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not check docker-compose status\")\n",
    "            print(f\"   Error: {result.stderr}\")\n",
    "            print(\"\\n   Manual check: Run 'docker-compose up -d' then 'docker-compose ps'\\n\")\n",
    "            return False\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  WARNING: docker or docker-compose command not found\")\n",
    "        print(\"   Install Docker and Docker Compose to verify locally\")\n",
    "        print(\"   For cloud deployment, this will be handled by the platform\\n\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error checking Docker: {e}\")\n",
    "        print(\"   This check will be skipped\\n\")\n",
    "        return False\n",
    "\n",
    "# Run the check\n",
    "check_docker_compose_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_header",
   "metadata": {},
   "source": [
    "## Section 3: CHECK - Environment Variables Documentation\n",
    "\n",
    "**Requirement:** All environment variables documented in .env.example\n",
    "\n",
    "**Impact:** Missing environment variables cause production startup failures - prevents 40% of deployment issues\n",
    "\n",
    "**What to verify:**\n",
    "- `.env.example` file exists with placeholder values (no secrets)\n",
    "- All required variables are documented\n",
    "- Each variable has a descriptive comment or example value\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_intro",
   "metadata": {},
   "source": [
    "**What this check does:** Scans for .env.example, compares it with .env (if present), and validates that no real secrets are committed. Uses pattern matching to detect common secret formats like OpenAI API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section3_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def check_env_example():\n",
    "    \"\"\"Check if .env.example exists and is properly documented\"\"\"\n",
    "    print(\"üîç Checking .env.example Completeness...\\n\")\n",
    "    \n",
    "    env_example_path = '.env.example'\n",
    "    env_path = '.env'\n",
    "    \n",
    "    # Check if .env.example exists\n",
    "    if not os.path.exists(env_example_path):\n",
    "        print(\"‚ùå FAIL: .env.example not found\")\n",
    "        print(\"\\nüìã Action Required:\")\n",
    "        print(\"   1. Create .env.example with all required environment variables\")\n",
    "        print(\"   2. Use placeholder values (NO SECRETS)\")\n",
    "        print(\"   3. Add comments explaining each variable\\n\")\n",
    "        print(\"Example .env.example content:\")\n",
    "        print(\"   # API Keys\")\n",
    "        print(\"   OPENAI_API_KEY=sk-your-key-here\")\n",
    "        print(\"   # Database\")\n",
    "        print(\"   DATABASE_URL=postgresql://user:pass@localhost:5432/dbname\")\n",
    "        print(\"   # Redis\")\n",
    "        print(\"   REDIS_URL=redis://localhost:6379\\n\")\n",
    "        return False\n",
    "    \n",
    "    # Read .env.example\n",
    "    with open(env_example_path, 'r') as f:\n",
    "        example_content = f.read()\n",
    "    \n",
    "    # Parse environment variables from .env.example\n",
    "    example_vars = set()\n",
    "    for line in example_content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#') and '=' in line:\n",
    "            var_name = line.split('=')[0].strip()\n",
    "            example_vars.add(var_name)\n",
    "    \n",
    "    print(f\"‚úì .env.example found with {len(example_vars)} variables\\n\")\n",
    "    \n",
    "    if len(example_vars) == 0:\n",
    "        print(\"‚ö†Ô∏è  WARNING: .env.example exists but has no variables defined\")\n",
    "        return False\n",
    "    \n",
    "    print(\"Variables in .env.example:\")\n",
    "    for var in sorted(example_vars):\n",
    "        print(f\"   ‚Ä¢ {var}\")\n",
    "    print()\n",
    "    \n",
    "    # Check if .env exists and compare\n",
    "    if os.path.exists(env_path):\n",
    "        with open(env_path, 'r') as f:\n",
    "            env_content = f.read()\n",
    "        \n",
    "        env_vars = set()\n",
    "        for line in env_content.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                var_name = line.split('=')[0].strip()\n",
    "                env_vars.add(var_name)\n",
    "        \n",
    "        # Find variables in .env but not in .env.example\n",
    "        missing_in_example = env_vars - example_vars\n",
    "        if missing_in_example:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Variables in .env but NOT in .env.example:\")\n",
    "            for var in sorted(missing_in_example):\n",
    "                print(f\"   ‚Ä¢ {var}\")\n",
    "            print(\"\\n   These should be added to .env.example (with placeholder values)\\n\")\n",
    "            return False\n",
    "        \n",
    "        # Find variables in .env.example but not in .env\n",
    "        missing_in_env = example_vars - env_vars\n",
    "        if missing_in_env:\n",
    "            print(\"‚ÑπÔ∏è  INFO: Variables in .env.example but not in .env:\")\n",
    "            for var in sorted(missing_in_env):\n",
    "                print(f\"   ‚Ä¢ {var}\")\n",
    "            print(\"\\n   (This is OK if these are optional or environment-specific)\\n\")\n",
    "    \n",
    "    # Check for common security issues in .env.example\n",
    "    security_issues = []\n",
    "    common_secret_patterns = [\n",
    "        (r'sk-[a-zA-Z0-9]{32,}', 'OpenAI API key'),\n",
    "        (r'[a-f0-9]{32,}', 'Potential secret token'),\n",
    "        (r'password[\"\\']?\\s*[:=]\\s*[\"\\']?[^\\s\"\\']+', 'Password value')\n",
    "    ]\n",
    "    \n",
    "    for pattern, desc in common_secret_patterns:\n",
    "        if re.search(pattern, example_content, re.IGNORECASE):\n",
    "            security_issues.append(desc)\n",
    "    \n",
    "    if security_issues:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Potential secrets detected in .env.example:\")\n",
    "        for issue in security_issues:\n",
    "            print(f\"   ‚Ä¢ {issue}\")\n",
    "        print(\"\\n   .env.example should only contain PLACEHOLDER values, not real secrets\\n\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ PASS: .env.example is properly documented\")\n",
    "    print(\"   All variables have placeholder values, no secrets detected\\n\")\n",
    "    return True\n",
    "\n",
    "# Run the check\n",
    "check_env_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_header",
   "metadata": {},
   "source": [
    "## Section 4: CHECK - Git History Secrets Scan\n",
    "\n",
    "**Requirement:** GitHub repository with clean history (no .env committed)\n",
    "\n",
    "**Impact:** Leaked secrets in Git history require repository deletion and recreation - costs 2-4 hours to clean up\n",
    "\n",
    "**What to verify:**\n",
    "- Run `git log --all --full-history -- .env` returns nothing (file never committed)\n",
    "- Check that .env is in .gitignore\n",
    "- Verify no secrets in any committed files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_intro",
   "metadata": {},
   "source": [
    "**What this check does:** Searches Git history for sensitive files (.env, secrets.json, credentials.json), validates .gitignore patterns, and scans committed files for suspicious names. Skips gracefully if Git is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section4_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_git_secrets():\n",
    "    \"\"\"Check if secrets have been committed to git history\"\"\"\n",
    "    print(\"üîç Checking Git History for Secrets...\\n\")\n",
    "    \n",
    "    # Offline-friendly: Skip if not a git repository\n",
    "    if not os.path.exists('.git'):\n",
    "        print(\"‚ö†Ô∏è  WARNING: Not a git repository\")\n",
    "        print(\"   Initialize git with: git init\")\n",
    "        print(\"   This check will be skipped\\n\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Offline-friendly: Skip if git not available\n",
    "        result = subprocess.run(['git', '--version'], \n",
    "                              capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Git is not available\")\n",
    "            print(\"   This check will be skipped\\n\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úì Git detected: {result.stdout.strip()}\\n\")\n",
    "        \n",
    "        # Check if .env is in git history\n",
    "        sensitive_files = ['.env', '.env.local', '.env.production', 'secrets.json', 'credentials.json']\n",
    "        found_secrets = []\n",
    "        \n",
    "        for file in sensitive_files:\n",
    "            result = subprocess.run(\n",
    "                ['git', 'log', '--all', '--full-history', '--', file],\n",
    "                capture_output=True, text=True, timeout=10\n",
    "            )\n",
    "            \n",
    "            if result.stdout.strip():\n",
    "                found_secrets.append(file)\n",
    "        \n",
    "        if found_secrets:\n",
    "            print(\"‚ùå FAIL: Sensitive files found in git history:\")\n",
    "            for file in found_secrets:\n",
    "                print(f\"   ‚Ä¢ {file}\")\n",
    "            print(\"\\nüö® CRITICAL: These files contain secrets and should NEVER be in git!\")\n",
    "            print(\"\\nüìã Action Required:\")\n",
    "            print(\"   Option 1 (Recommended if repo not shared):\")\n",
    "            print(\"      1. Use git filter-branch or BFG Repo-Cleaner to remove from history\")\n",
    "            print(\"      2. Force push to remote (WARNING: Destructive)\")\n",
    "            print(\"\\n   Option 2 (If already shared publicly):\")\n",
    "            print(\"      1. Rotate ALL secrets immediately\")\n",
    "            print(\"      2. Create new repository\")\n",
    "            print(\"      3. Migrate code without sensitive files\\n\")\n",
    "            return False\n",
    "        \n",
    "        print(\"‚úì No sensitive files (.env, secrets.json, etc.) found in git history\\n\")\n",
    "        \n",
    "        # Check if .gitignore exists and includes .env\n",
    "        if os.path.exists('.gitignore'):\n",
    "            with open('.gitignore', 'r') as f:\n",
    "                gitignore_content = f.read()\n",
    "            \n",
    "            # Check for common patterns\n",
    "            patterns_to_check = ['.env', '*.env', '.env.*']\n",
    "            found_patterns = []\n",
    "            \n",
    "            for pattern in patterns_to_check:\n",
    "                if pattern in gitignore_content:\n",
    "                    found_patterns.append(pattern)\n",
    "            \n",
    "            if found_patterns:\n",
    "                print(\"‚úì .gitignore includes environment file patterns:\")\n",
    "                for pattern in found_patterns:\n",
    "                    print(f\"   ‚Ä¢ {pattern}\")\n",
    "                print()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  WARNING: .gitignore exists but doesn't include .env patterns\")\n",
    "                print(\"   Add these lines to .gitignore:\")\n",
    "                print(\"      .env\")\n",
    "                print(\"      .env.*\")\n",
    "                print(\"      !.env.example\\n\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  WARNING: .gitignore not found\")\n",
    "            print(\"   Create .gitignore with at minimum:\")\n",
    "            print(\"      .env\")\n",
    "            print(\"      .env.*\")\n",
    "            print(\"      !.env.example\")\n",
    "            print(\"      __pycache__/\")\n",
    "            print(\"      *.pyc\")\n",
    "            print(\"      venv/\")\n",
    "            print(\"      .venv/\\n\")\n",
    "            return False\n",
    "        \n",
    "        # Check for accidentally committed secrets in current files\n",
    "        print(\"üîç Scanning current committed files for potential secrets...\\n\")\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            ['git', 'ls-files'],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            committed_files = result.stdout.strip().split('\\n')\n",
    "            suspicious_files = [f for f in committed_files if any(\n",
    "                keyword in f.lower() for keyword in ['secret', 'password', 'credential', 'key', 'token']\n",
    "            )]\n",
    "            \n",
    "            if suspicious_files:\n",
    "                print(\"‚ö†Ô∏è  WARNING: Files with suspicious names found in git:\")\n",
    "                for file in suspicious_files[:10]:  # Show first 10\n",
    "                    print(f\"   ‚Ä¢ {file}\")\n",
    "                if len(suspicious_files) > 10:\n",
    "                    print(f\"   ... and {len(suspicious_files) - 10} more\")\n",
    "                print(\"\\n   Review these files to ensure they don't contain real secrets\\n\")\n",
    "        \n",
    "        print(\"‚úÖ PASS: Git history is clean, no secrets detected\")\n",
    "        print(\"   .gitignore properly configured\\n\")\n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  WARNING: git command not found\")\n",
    "        print(\"   Install Git to verify history\\n\")\n",
    "        return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Git command timed out\")\n",
    "        print(\"   Repository might be too large, check manually\\n\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error checking git history: {e}\")\n",
    "        print(\"   Manual check: Run 'git log --all --full-history -- .env'\\n\")\n",
    "        return False\n",
    "\n",
    "# Run the check\n",
    "check_git_secrets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_header",
   "metadata": {},
   "source": [
    "## Section 5: OPTIONAL - Staging Configuration\n",
    "\n",
    "**Requirement:** At least Easy challenge completed (staging configuration)\n",
    "\n",
    "**Impact:** Understanding multi-environment setup prevents production configuration mistakes - saves 60-90 minutes of trial-and-error\n",
    "\n",
    "**What to verify:**\n",
    "- Separate `docker-compose.staging.yml` exists and works locally\n",
    "- Environment-specific configurations are properly separated\n",
    "- Production and staging differences are documented\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_intro",
   "metadata": {},
   "source": [
    "**What this check does:** Searches for staging compose files (docker-compose.staging.yml, docker-compose.dev.yml), validates environment-specific configurations, and provides a template if none exists. This check is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section5_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_staging_config():\n",
    "    \"\"\"Check if staging configuration exists\"\"\"\n",
    "    print(\"üîç Checking Staging Configuration (Optional)...\\n\")\n",
    "    \n",
    "    staging_files = [\n",
    "        'docker-compose.staging.yml',\n",
    "        'docker-compose.stage.yml',\n",
    "        'docker-compose.dev.yml'\n",
    "    ]\n",
    "    \n",
    "    found_staging = None\n",
    "    for file in staging_files:\n",
    "        if os.path.exists(file):\n",
    "            found_staging = file\n",
    "            break\n",
    "    \n",
    "    if found_staging:\n",
    "        print(f\"‚úì Staging configuration found: {found_staging}\\n\")\n",
    "        \n",
    "        # Read and display some info\n",
    "        with open(found_staging, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        lines = len(content.split('\\n'))\n",
    "        print(f\"   File size: {lines} lines\\n\")\n",
    "        \n",
    "        # Check for environment-specific configurations\n",
    "        env_indicators = ['environment:', 'env_file:', 'NODE_ENV', 'ENVIRONMENT', 'STAGE']\n",
    "        found_indicators = [ind for ind in env_indicators if ind in content]\n",
    "        \n",
    "        if found_indicators:\n",
    "            print(\"‚úì Environment-specific configurations detected:\")\n",
    "            for ind in found_indicators:\n",
    "                print(f\"   ‚Ä¢ {ind}\")\n",
    "            print()\n",
    "        \n",
    "        print(\"‚úÖ PASS: Staging configuration exists\")\n",
    "        print(\"   You have experience with multi-environment setup\\n\")\n",
    "        \n",
    "        print(\"üí° TIP: For production deployment, consider these differences:\")\n",
    "        print(\"   ‚Ä¢ Use managed databases instead of local containers\")\n",
    "        print(\"   ‚Ä¢ Enable HTTPS/SSL certificates\")\n",
    "        print(\"   ‚Ä¢ Set appropriate resource limits\")\n",
    "        print(\"   ‚Ä¢ Configure logging and monitoring\")\n",
    "        print(\"   ‚Ä¢ Use secrets management (not .env files)\\n\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  INFO: No staging configuration found\")\n",
    "        print(\"   This is optional but recommended\\n\")\n",
    "        \n",
    "        print(\"üìã Create docker-compose.staging.yml with this template:\\n\")\n",
    "        template = \"\"\"version: '3.8'\n",
    "\n",
    "services:\n",
    "  app:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - NODE_ENV=staging\n",
    "      - LOG_LEVEL=info\n",
    "    env_file:\n",
    "      - .env.staging\n",
    "    depends_on:\n",
    "      - redis\n",
    "      - db\n",
    "\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "\n",
    "  db:\n",
    "    image: postgres:15-alpine\n",
    "    environment:\n",
    "      - POSTGRES_DB=myapp_staging\n",
    "      - POSTGRES_USER=staging_user\n",
    "      - POSTGRES_PASSWORD=${DB_PASSWORD}\n",
    "    volumes:\n",
    "      - staging_db_data:/var/lib/postgresql/data\n",
    "\n",
    "volumes:\n",
    "  staging_db_data:\n",
    "\"\"\"\n",
    "        print(template)\n",
    "        print(\"\\n‚ö†Ô∏è  OPTIONAL: Complete this for better production readiness\")\n",
    "        print(\"   Skip if you're comfortable learning multi-environment setup during cloud deployment\\n\")\n",
    "        \n",
    "        return None  # Optional, so not a failure\n",
    "\n",
    "# Run the check\n",
    "check_staging_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6_header",
   "metadata": {},
   "source": [
    "## Section 6: CALL-FORWARD - What's Next in M3.2\n",
    "\n",
    "### M3.2: Cloud Deployment (Railway/Render)\n",
    "\n",
    "You're ready to deploy your containerized RAG system to production cloud platforms!\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Deploy\n",
    "\n",
    "#### 1. Railway Deployment (Fast & Developer-Friendly)\n",
    "\n",
    "**Key Features:**\n",
    "- Deploy your containerized stack in under 10 minutes\n",
    "- Automatic PostgreSQL and Redis provisioning\n",
    "- Zero infrastructure configuration required\n",
    "- Continuous deployment from GitHub\n",
    "\n",
    "**Trade-offs:**\n",
    "- Free tier services cold-start after 15 minutes of inactivity (30-60 second wake time)\n",
    "- Acceptable for development\n",
    "- Paid tier ($7/month) required for always-on production use\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Render Deployment (Production-Grade with Great Docs)\n",
    "\n",
    "**Key Features:**\n",
    "- Deploy the same containers with custom domain configuration\n",
    "- Managed services with excellent documentation\n",
    "- More configuration options for fine-tuning\n",
    "- Production-grade reliability\n",
    "\n",
    "**Comparison:** Platform comparison included to help you choose the right fit\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Automatic Deployments from GitHub\n",
    "\n",
    "**Modern DevOps Without Complex CI/CD:**\n",
    "- Every push to main automatically triggers deployment\n",
    "- Change code, push, and production updates in 3-5 minutes\n",
    "- No manual deployment steps\n",
    "- No complex pipeline configuration\n",
    "\n",
    "---\n",
    "\n",
    "### The Core Question M3.2 Answers\n",
    "\n",
    "**\"How do I deploy Docker containers to production without managing servers, configuring load balancers, or handling SSL certificates?\"**\n",
    "\n",
    "**Answer:** Use platform-as-a-service (PaaS) providers that:\n",
    "- Detect your Dockerfile automatically\n",
    "- Build images in the cloud\n",
    "- Provision managed databases\n",
    "- Handle HTTPS and custom domains\n",
    "- Scale on demand\n",
    "\n",
    "**Railway** specializes in speed and developer experience  \n",
    "**Render** specializes in stability and documentation\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Have After M3.2\n",
    "\n",
    "By the end of M3.2, you will have:\n",
    "- Two production deployments (Railway + Render)\n",
    "- Public URLs with HTTPS enabled\n",
    "- Automatic deployments on every git push\n",
    "- Knowledge to choose the right platform for your needs\n",
    "- Experience with modern cloud deployment workflows\n",
    "\n",
    "---\n",
    "\n",
    "### Estimated Time\n",
    "- Video: 35 minutes\n",
    "- Hands-on deployment and testing: 90 minutes\n",
    "- Total: ~2 hours\n",
    "\n",
    "---\n",
    "\n",
    "### Before You Continue\n",
    "\n",
    "**Verify all checks above passed:**\n",
    "- ‚úÖ Docker compose health check\n",
    "- ‚úÖ .env.example completeness\n",
    "- ‚úÖ Git history secrets scan\n",
    "- ‚úÖ (Optional) Staging configuration\n",
    "\n",
    "**If any required checks failed, fix them before proceeding to M3.2!**\n",
    "\n",
    "---\n",
    "\n",
    "**See you in M3.2: Cloud Deployment (Railway/Render)!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
