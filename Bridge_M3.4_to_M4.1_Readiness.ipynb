{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge M3.4 ‚Üí M4.1 Readiness Validation\n",
    "\n",
    "**Duration:** 15-20 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "You've completed Module 3: Production Deployment ‚Äî your RAG system is containerized, deployed to the cloud, secured with authentication and rate limiting, and tested under load. Before advancing to Module 4 (Advanced RAG Techniques), you need to validate that your production infrastructure is truly ready.\n",
    "\n",
    "**The shift:** From \"working in production\" to \"production-ready for advanced features.\" Missing CI/CD, monitoring, or capacity docs makes debugging hybrid search (M4.1) exponentially harder.\n",
    "\n",
    "**Why it matters:** Module 4 assumes you can measure performance changes, catch regressions, and scale when needed. This notebook validates those foundations are in place.\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts Covered\n",
    "\n",
    "**Delta from M3.4 to M4.1 readiness:**\n",
    "- Automated CI/CD with load testing (catches regressions before production)\n",
    "- Production-like staging data (‚â•1000 docs, not 10 test docs)\n",
    "- Proactive monitoring alerts (error rate, latency, traffic spikes)\n",
    "- Documented capacity limits and scaling triggers\n",
    "- Understanding hybrid search trade-offs (latency, complexity, cost)\n",
    "\n",
    "---\n",
    "\n",
    "## After Completing\n",
    "\n",
    "You will be able to:\n",
    "- ‚úÖ Verify CI/CD pipeline exists with automated load testing (or create sample workflow)\n",
    "- ‚úÖ Confirm staging environment has production-scale data (‚â•1000 documents)\n",
    "- ‚úÖ Validate monitoring alerts are configured for critical thresholds\n",
    "- ‚úÖ Check capacity documentation exists (QPS, bottlenecks, scaling strategy)\n",
    "- ‚úÖ Understand when hybrid search is worth the trade-offs (and when it's not)\n",
    "- ‚úÖ Confidently proceed to M4.1 with production foundations in place\n",
    "\n",
    "---\n",
    "\n",
    "## Context in Track\n",
    "\n",
    "**Bridge: L1.M3 ‚Üí L1.M4**\n",
    "\n",
    "- **Previous:** M3.4 Load Testing & Scaling (capacity measurement, bottleneck identification)\n",
    "- **This Bridge:** Validate production readiness checklist before advanced techniques\n",
    "- **Next:** M4.1 Hybrid Search (dense + sparse vectors for exact-match queries)\n",
    "\n",
    "---\n",
    "\n",
    "## Run Locally\n",
    "\n",
    "**Windows (PowerShell):**\n",
    "```powershell\n",
    "$env:PYTHONPATH=\"$PWD\"; jupyter notebook Bridge_M3.4_to_M4.1_Readiness.ipynb\n",
    "```\n",
    "\n",
    "**macOS/Linux (bash):**\n",
    "```bash\n",
    "export PYTHONPATH=\"$PWD\" && jupyter notebook Bridge_M3.4_to_M4.1_Readiness.ipynb\n",
    "```\n",
    "\n",
    "**Note:** This notebook runs offline-friendly checks. It creates sample files when external systems aren't accessible.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Module 3 Achievements Recap\n",
    "\n",
    "### What You Built in Module 3: Production Deployment\n",
    "\n",
    "You completed a major milestone - transforming a prototype RAG system into a production-ready application.\n",
    "\n",
    "#### M3.1: Containerization with Docker\n",
    "‚úÖ **Packaged** RAG system into portable Docker containers with multi-stage builds\n",
    "‚úÖ **Orchestrated** FastAPI, Redis, and PostgreSQL with docker-compose.yml\n",
    "‚úÖ **Implemented** volume mounts for persistence and health checks for reliability\n",
    "‚úÖ **Built** production-ready images deployable to any cloud platform\n",
    "\n",
    "#### M3.2: Cloud Deployment (Railway/Render)\n",
    "‚úÖ **Deployed** containerized system to Railway and Render cloud platforms\n",
    "‚úÖ **Configured** environment variables and secrets management for API keys\n",
    "‚úÖ **Set up** custom domains with SSL/TLS certificates for production traffic\n",
    "‚úÖ **Implemented** CI/CD pipelines with GitHub Actions for automated deployments\n",
    "\n",
    "#### M3.3: API Development & Security\n",
    "‚úÖ **Secured** API with token-based authentication and role-based access control\n",
    "‚úÖ **Implemented** rate limiting (10 req/min free, 100/min premium)\n",
    "‚úÖ **Added** input validation with Pydantic to prevent injection attacks\n",
    "‚úÖ **Built** comprehensive error handling with user-friendly messages\n",
    "\n",
    "#### M3.4: Load Testing & Scaling\n",
    "‚úÖ **Designed** comprehensive load tests using Locust to measure capacity\n",
    "‚úÖ **Identified** bottlenecks (OpenAI rate limits, DB connections, memory leaks)\n",
    "‚úÖ **Implemented** caching and batching optimizations (2-10x capacity increase)\n",
    "‚úÖ **Configured** horizontal scaling with load balancing and health checks\n",
    "\n",
    "---\n",
    "\n",
    "### Your Production-Ready System\n",
    "\n",
    "You now have a RAG system that is:\n",
    "- **Containerized** for consistent deployment anywhere\n",
    "- **Deployed** to production cloud platforms with SSL\n",
    "- **Secured** against attacks with authentication, rate limiting, and validation\n",
    "- **Tested** under load with documented capacity limits\n",
    "\n",
    "**This is portfolio-worthy work.** Many senior engineers don't have these production deployment skills.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: CI/CD Pipeline Validation\n",
    "\n",
    "**Checklist Item 1:** Implement CI/CD pipeline with automated load testing\n",
    "\n",
    "**Impact:** Catches performance regressions before production (prevents 80% of capacity issues)\n",
    "\n",
    "**Success Criteria:**\n",
    "- ‚úÖ `.github/workflows/*.yml` exists with test + load test stages\n",
    "- ‚úÖ Tests run on every PR\n",
    "- ‚úÖ Performance doesn't degrade >10%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 2.1: Verify CI/CD Workflow Files Exist\n",
    "\n",
    "Scan for GitHub Actions workflow files in `.github/workflows/`. If found, validation passes; if missing, we'll create a sample workflow in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Check for CI/CD workflow files\n",
    "workflows_dir = Path(\".github/workflows\")\n",
    "result = {\"status\": \"‚ùå FAIL\", \"message\": \"\", \"action\": \"\"}\n",
    "\n",
    "if workflows_dir.exists():\n",
    "    yaml_files = list(workflows_dir.glob(\"*.yml\")) + list(workflows_dir.glob(\"*.yaml\"))\n",
    "    if yaml_files:\n",
    "        result[\"status\"] = \"‚úÖ PASS\"\n",
    "        result[\"message\"] = f\"Found {len(yaml_files)} workflow file(s)\"\n",
    "        print(f\"‚úÖ CI/CD workflows found: {[f.name for f in yaml_files]}\")\n",
    "    else:\n",
    "        result[\"status\"] = \"‚ùå FAIL\"\n",
    "        result[\"message\"] = \"No .yml/.yaml files in .github/workflows/\"\n",
    "        result[\"action\"] = \"Create sample workflow in ./ci_samples/\"\n",
    "else:\n",
    "    result[\"status\"] = \"‚ùå FAIL\"\n",
    "    result[\"message\"] = \".github/workflows/ directory not found\"\n",
    "    result[\"action\"] = \"Create sample workflow in ./ci_samples/\"\n",
    "\n",
    "print(f\"Status: {result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 2.2: Create Sample Workflow if Missing\n",
    "\n",
    "If no CI/CD workflow exists, generate a sample GitHub Actions workflow with unit tests, integration tests, and a small load test. You can copy this to `.github/workflows/` and customize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CI/CD not found, create sample workflow (offline-friendly)\n",
    "if result[\"status\"] == \"‚ùå FAIL\":\n",
    "    sample_dir = Path(\"./ci_samples\")\n",
    "    sample_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    sample_workflow = \"\"\"name: Test and Load Test\n",
    "on: [pull_request]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.9'\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "      - name: Run unit tests\n",
    "        run: pytest tests/unit\n",
    "      - name: Run integration tests\n",
    "        run: pytest tests/integration\n",
    "      - name: Run load test (20 users, 2 min)\n",
    "        run: locust -f load_test.py --headless -u 20 -r 5 -t 2m\n",
    "      - name: Check performance (P95 < baseline + 10%)\n",
    "        run: python scripts/check_performance.py\n",
    "\"\"\"\n",
    "    \n",
    "    sample_path = sample_dir / \"test_workflow.yml\"\n",
    "    sample_path.write_text(sample_workflow)\n",
    "    print(f\"üìù Created sample workflow: {sample_path}\")\n",
    "    print(\"   ‚Üí Copy to .github/workflows/ and customize for your project\")\n",
    "else:\n",
    "    print(\"‚úÖ CI/CD validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Staging Environment Data Volume\n",
    "\n",
    "**Checklist Item 2:** Deploy to staging environment with production-like data\n",
    "\n",
    "**Impact:** Validates behavior at scale before real users are affected\n",
    "\n",
    "**Success Criteria:**\n",
    "- ‚úÖ Staging has ‚â•1000 documents (not just 10 test docs)\n",
    "- ‚úÖ Real query patterns, not synthetic tests\n",
    "- ‚úÖ Load tests in staging accurately predict production behavior\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 3.1: Verify Staging Document Count\n",
    "\n",
    "Look for a `staging_metrics.json` file with document count. If it exists and has ‚â•1000 documents, validation passes. This is an offline-friendly check that doesn't require live staging access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check staging document count (offline-friendly: uses local file)\n",
    "staging_file = Path(\"./staging_metrics.json\")\n",
    "\n",
    "if staging_file.exists():\n",
    "    try:\n",
    "        metrics = json.loads(staging_file.read_text())\n",
    "        doc_count = metrics.get(\"document_count\", 0)\n",
    "        \n",
    "        if doc_count >= 1000:\n",
    "            print(f\"‚úÖ PASS: Staging has {doc_count:,} documents (‚â•1000)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: Staging has only {doc_count} documents (need ‚â•1000)\")\n",
    "            print(\"   ‚Üí Load production-like data volume for accurate testing\")\n",
    "    except (json.JSONDecodeError, IOError) as e:\n",
    "        print(f\"‚ö†Ô∏è  ERROR: Could not read staging_metrics.json: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå FAIL: staging_metrics.json not found\")\n",
    "    print(\"   ‚Üí Manually verify staging document count or create staging_metrics.json\")\n",
    "    print(\"   Format: {\\\"document_count\\\": 1500, \\\"query_count_24h\\\": 2000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 3.2: Create Sample Staging Metrics File\n",
    "\n",
    "If the staging metrics file doesn't exist, create a template you can populate with actual staging data. Update `document_count` with your real staging environment's document count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample staging metrics file if missing (offline-friendly stub)\n",
    "if not staging_file.exists():\n",
    "    sample_metrics = {\n",
    "        \"document_count\": 0,\n",
    "        \"query_count_24h\": 0,\n",
    "        \"last_updated\": \"2025-11-09T00:00:00Z\",\n",
    "        \"note\": \"Update with actual staging environment metrics\"\n",
    "    }\n",
    "    \n",
    "    staging_file.write_text(json.dumps(sample_metrics, indent=2))\n",
    "    print(f\"üìù Created {staging_file}\")\n",
    "    print(\"   ‚Üí Update document_count with actual staging data\")\n",
    "    print(\"   ‚Üí Example: curl https://your-staging.app/metrics > staging_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Monitoring Alerts Configuration\n",
    "\n",
    "**Checklist Item 3:** Set up monitoring alerts for capacity thresholds\n",
    "\n",
    "**Impact:** Proactive notification before system crashes (reduces downtime by 90%)\n",
    "\n",
    "**Success Criteria:**\n",
    "- ‚úÖ Alerts configured for error rate >5%\n",
    "- ‚úÖ Alerts configured for P99 latency >10s\n",
    "- ‚úÖ Alerts configured for unusual traffic spikes\n",
    "- ‚úÖ Alerts have been deliberately triggered to confirm they fire\n",
    "\n",
    "**Key Metrics to Monitor:**\n",
    "- Error rate threshold: >5% over 5-minute window\n",
    "- P99 latency threshold: >10 seconds\n",
    "- Traffic spike: >2x normal rate in 5 minutes\n",
    "- Memory usage: >85% of available\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 4.1: Verify Alert Configuration Files Exist\n",
    "\n",
    "Search for common alert configuration files (Prometheus, Grafana, etc.). If found, remind to verify they include the critical alerts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for monitoring/alerts configuration (offline-friendly)\n",
    "alert_files = [\n",
    "    Path(\"./monitoring/alerts.yml\"),\n",
    "    Path(\"./monitoring/alerts.yaml\"),\n",
    "    Path(\"./alerts.yml\"),\n",
    "    Path(\"./prometheus/alerts.yml\"),\n",
    "    Path(\"./grafana/alerts.json\")\n",
    "]\n",
    "\n",
    "alerts_found = [f for f in alert_files if f.exists()]\n",
    "\n",
    "if alerts_found:\n",
    "    print(f\"‚úÖ PASS: Found alert configuration: {[str(f) for f in alerts_found]}\")\n",
    "    for alert_file in alerts_found:\n",
    "        print(f\"   ‚Üí Review {alert_file} for error rate, latency, traffic alerts\")\n",
    "else:\n",
    "    print(\"‚ùå FAIL: No alert configuration files found\")\n",
    "    print(\"   ‚Üí Will create sample alerts_example.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 4.2: Create Sample Alert Configuration\n",
    "\n",
    "If no alert configuration exists, generate a sample Prometheus alerts file with the four critical alerts: error rate, P99 latency, traffic spikes, and memory usage. Integrate this with your monitoring system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample alerts configuration if missing (offline-friendly stub)\n",
    "if not alerts_found:\n",
    "    sample_alerts = \"\"\"# Sample Prometheus Alerts for RAG System\n",
    "groups:\n",
    "  - name: rag_system_alerts\n",
    "    interval: 30s\n",
    "    rules:\n",
    "      - alert: HighErrorRate\n",
    "        expr: rate(http_requests_total{status=~\"5..\"}[5m]) > 0.05\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: critical\n",
    "        annotations:\n",
    "          summary: \"Error rate >5% for 5 minutes\"\n",
    "          description: \"{{ $value }}% of requests failing\"\n",
    "\n",
    "      - alert: HighP99Latency\n",
    "        expr: histogram_quantile(0.99, http_request_duration_seconds_bucket) > 10\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: warning\n",
    "        annotations:\n",
    "          summary: \"P99 latency >10s\"\n",
    "          description: \"{{ $value }}s P99 latency detected\"\n",
    "\n",
    "      - alert: TrafficSpike\n",
    "        expr: rate(http_requests_total[5m]) > 2 * avg_over_time(rate(http_requests_total[1h])[1h:5m])\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: warning\n",
    "        annotations:\n",
    "          summary: \"Traffic spike detected (>2x normal)\"\n",
    "\n",
    "      - alert: HighMemoryUsage\n",
    "        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.85\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: warning\n",
    "        annotations:\n",
    "          summary: \"Memory usage >85%\"\n",
    "\"\"\"\n",
    "    \n",
    "    alerts_path = Path(\"./alerts_example.yaml\")\n",
    "    alerts_path.write_text(sample_alerts)\n",
    "    print(f\"üìù Created {alerts_path}\")\n",
    "    print(\"   ‚Üí Integrate with Prometheus, Grafana, or cloud monitoring\")\n",
    "    print(\"   ‚Üí Test alerts: deliberately trigger high error rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Capacity Documentation\n",
    "\n",
    "**Checklist Item 4:** Document capacity limits and scaling triggers\n",
    "\n",
    "**Impact:** Clear guidance for when to scale (prevents both over-provisioning and crashes)\n",
    "\n",
    "**Success Criteria:**\n",
    "- ‚úÖ Documentation includes current capacity (concurrent users, QPS)\n",
    "- ‚úÖ Identified bottlenecks documented\n",
    "- ‚úÖ Scaling strategy clearly defined\n",
    "- ‚úÖ Anyone can read docs and know how to scale the system\n",
    "\n",
    "**Required Documentation:**\n",
    "- Current capacity: e.g., \"125 concurrent users at 5 QPS/user\"\n",
    "- P95/P99 latency at various loads\n",
    "- Identified bottlenecks: OpenAI rate limits, DB connections, memory\n",
    "- Scaling triggers: \"Scale horizontally when CPU >70% for 10 min\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 5.1: Verify Capacity Documentation Exists\n",
    "\n",
    "Search for capacity documentation files and scan their contents for key sections: capacity limits, bottlenecks, and scaling strategy. If found with all three, validation passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for capacity documentation (offline-friendly)\n",
    "capacity_docs = [\n",
    "    Path(\"./CAPACITY.md\"),\n",
    "    Path(\"./docs/capacity.md\"),\n",
    "    Path(\"./capacity_baseline.md\"),\n",
    "    Path(\"./README.md\")  # May contain capacity section\n",
    "]\n",
    "\n",
    "capacity_found = [f for f in capacity_docs if f.exists()]\n",
    "\n",
    "if capacity_found:\n",
    "    print(f\"‚úÖ Found documentation: {[str(f) for f in capacity_found]}\")\n",
    "    print(\"   ‚Üí Verify it includes: capacity limits, bottlenecks, scaling strategy\")\n",
    "    \n",
    "    # Quick scan for key terms\n",
    "    for doc in capacity_found:\n",
    "        try:\n",
    "            content = doc.read_text().lower()\n",
    "            has_capacity = \"capacity\" in content or \"concurrent\" in content\n",
    "            has_bottleneck = \"bottleneck\" in content\n",
    "            has_scaling = \"scal\" in content\n",
    "            \n",
    "            if has_capacity and has_bottleneck and has_scaling:\n",
    "                print(f\"   ‚úÖ {doc.name} appears complete (has capacity, bottlenecks, scaling)\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  {doc.name} may be missing key sections\")\n",
    "        except IOError as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not read {doc.name}: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå FAIL: No capacity documentation found\")\n",
    "    print(\"   ‚Üí Will create capacity_baseline.md template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 5.2: Create Capacity Baseline Documentation\n",
    "\n",
    "If capacity documentation is missing, generate a comprehensive template with sections for performance metrics, bottlenecks, scaling strategy, and load test results. Fill this in with your actual load test data from M3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capacity baseline documentation if missing (offline-friendly stub)\n",
    "if not capacity_found or not any(doc.name != \"README.md\" for doc in capacity_found):\n",
    "    capacity_template = \"\"\"# RAG System Capacity Baseline\n",
    "\n",
    "**Last Updated:** 2025-11-09  \n",
    "**Environment:** Production / Staging  \n",
    "\n",
    "## Current Capacity\n",
    "\n",
    "### Performance Metrics\n",
    "- **Concurrent Users:** 125 users (measured via Locust)\n",
    "- **Queries Per Second (QPS):** 625 QPS peak (5 QPS/user)\n",
    "- **P50 Latency:** 800ms\n",
    "- **P95 Latency:** 1.2s\n",
    "- **P99 Latency:** 3.5s\n",
    "\n",
    "### Resource Usage at Peak\n",
    "- **CPU:** 65% average, 85% peak\n",
    "- **Memory:** 2.4GB / 4GB (60%)\n",
    "- **Database Connections:** 45 / 100\n",
    "- **OpenAI API Rate Limit:** 3,000 RPM (tier 1)\n",
    "\n",
    "---\n",
    "\n",
    "## Identified Bottlenecks\n",
    "\n",
    "1. **OpenAI API Rate Limits** (PRIMARY)\n",
    "   - Current limit: 3,000 requests/minute\n",
    "   - Blocks requests when exceeded\n",
    "   - **Impact:** Caps system at ~50 QPS with caching\n",
    "\n",
    "2. **Database Connection Pool**\n",
    "   - Max connections: 100\n",
    "   - Connection acquisition time increases at >80 active\n",
    "   - **Impact:** Latency spike at >80 concurrent users without caching\n",
    "\n",
    "3. **Memory Usage (Embedding Cache)**\n",
    "   - In-memory cache grows unbounded\n",
    "   - Risk of OOM at >10,000 unique queries/hour\n",
    "   - **Impact:** Requires cache eviction policy\n",
    "\n",
    "---\n",
    "\n",
    "## Scaling Strategy\n",
    "\n",
    "### Horizontal Scaling Triggers\n",
    "- **Scale UP:** CPU >70% for 10+ minutes\n",
    "- **Scale DOWN:** CPU <30% for 30+ minutes\n",
    "- **Target:** 3-5 instances behind load balancer\n",
    "\n",
    "### Optimization Checklist Before Scaling\n",
    "- ‚úÖ Enable Redis caching (reduces OpenAI calls by 60-80%)\n",
    "- ‚úÖ Implement request batching for embeddings\n",
    "- ‚úÖ Add database connection pooling with pgBouncer\n",
    "- ‚úÖ Implement LRU cache eviction for embeddings\n",
    "\n",
    "### Cost-Performance Trade-offs\n",
    "- **1 instance:** $50/mo, handles 50 concurrent users\n",
    "- **3 instances:** $150/mo, handles 150 concurrent users\n",
    "- **Caching (Redis):** +$10/mo, reduces API costs by $100-200/mo\n",
    "\n",
    "---\n",
    "\n",
    "## Load Test Results Summary\n",
    "\n",
    "| Test Date | Users | QPS | P95 Latency | Errors | Notes |\n",
    "|-----------|-------|-----|-------------|--------|-------|\n",
    "| 2025-10-15 | 100 | 500 | 1.1s | 0.2% | Baseline |\n",
    "| 2025-10-20 | 125 | 625 | 1.2s | 0.5% | Added caching |\n",
    "| 2025-10-25 | 150 | 750 | 2.8s | 5.1% | OpenAI rate limit hit |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Upgrade OpenAI tier (3K ‚Üí 10K RPM) for $200/mo\n",
    "2. Implement Redis distributed cache\n",
    "3. Add auto-scaling rules to Railway/Render\n",
    "4. Document incident response for rate limit errors\n",
    "\"\"\"\n",
    "    \n",
    "    baseline_path = Path(\"./capacity_baseline.md\")\n",
    "    baseline_path.write_text(capacity_template)\n",
    "    print(f\"üìù Created {baseline_path}\")\n",
    "    print(\"   ‚Üí Update with YOUR actual load test results from M3.4\")\n",
    "    print(\"   ‚Üí Include in README or docs/ folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Call-Forward ‚Äî Why Module 4.1 (Hybrid Search)\n",
    "\n",
    "### The Retrieval Quality Problem\n",
    "\n",
    "Your production RAG system uses **pure vector search** - converting text to embeddings and finding semantic similarity. This works beautifully for natural language queries like:\n",
    "- \"How do I secure user data?\"\n",
    "- \"What are best practices for API authentication?\"\n",
    "\n",
    "But vector embeddings **blur exact terms into semantic concepts**.\n",
    "\n",
    "---\n",
    "\n",
    "### When Vector Search Fails\n",
    "\n",
    "**Problem Queries:**\n",
    "- Product codes: `SKU-A1234`\n",
    "- Technical terms: `OAuth 2.0 client credentials flow`\n",
    "- Error codes: `ERR_CONNECTION_REFUSED`\n",
    "- API names: `stripe.checkout.Session.create()`\n",
    "\n",
    "Your system might return results about \"product codes\" or \"OAuth authentication\" - semantically similar, but **not the exact match** the user needs.\n",
    "\n",
    "---\n",
    "\n",
    "### Quantifying the Impact\n",
    "\n",
    "In production RAG systems for technical content:\n",
    "- **40-60% of technical queries** include exact terms (product codes, API names, error codes)\n",
    "- **Pure vector search misses 30-45%** of these exact matches\n",
    "- **Users retry queries 2-3 times** before finding the right document\n",
    "- **Customer support tickets increase 20-30%** from \"can't find documentation\"\n",
    "\n",
    "**Cost:** ‚Çπ15,000-50,000 per month in support time and user frustration for a 10,000 user system\n",
    "\n",
    "---\n",
    "\n",
    "### The Solution: Hybrid Search\n",
    "\n",
    "**M4.1 introduces Hybrid Search** - combining semantic embeddings (dense vectors) with BM25 keyword matching (sparse vectors).\n",
    "\n",
    "**Improvement:** 40-60% better exact match accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### Trade-offs to Consider\n",
    "\n",
    "Hybrid search is NOT free. You're trading improved accuracy for:\n",
    "\n",
    "#### 1. Doubled Infrastructure Complexity\n",
    "- **Two indexes to maintain:** Dense vectors (Pinecone) + Sparse vectors (BM25/Elasticsearch)\n",
    "- More code, more failure modes, more operational overhead\n",
    "\n",
    "#### 2. Increased Latency\n",
    "- **+80-120ms per query** (two retrieval operations instead of one)\n",
    "- P95 latency increases from 1.2s ‚Üí 1.3-1.4s\n",
    "\n",
    "#### 3. Higher Costs\n",
    "- **+$150-500/month** for Elasticsearch at scale (>100K documents)\n",
    "- Pinecone free tier only supports dense vectors; BM25 requires separate infrastructure\n",
    "\n",
    "---\n",
    "\n",
    "### When Hybrid Search Makes Sense\n",
    "\n",
    "‚úÖ **Use hybrid search when:**\n",
    "- Technical documentation (APIs, error codes, product SKUs)\n",
    "- E-commerce search (exact product names + semantic browsing)\n",
    "- Legal/medical documents (precise terminology matters)\n",
    "- User queries mix natural language + exact terms\n",
    "\n",
    "‚ùå **Skip hybrid search when:**\n",
    "- Purely conversational content (blog posts, articles)\n",
    "- Small document sets (<1000 docs)\n",
    "- Simplicity matters more than perfection\n",
    "- Budget/latency constraints are tight\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Build in M4.1\n",
    "\n",
    "You'll implement:\n",
    "1. **BM25 sparse retrieval** alongside your dense vectors\n",
    "2. **Reciprocal Rank Fusion (RRF)** to merge results from both systems\n",
    "3. **Alpha parameter tuning** (0=pure keyword, 1=pure semantic) based on query type\n",
    "4. **Decision framework** for when NOT to use hybrid search\n",
    "\n",
    "**Technical Preview:** By the end, you'll handle queries like \"SKU-A1234\" (exact match) and \"how to authenticate users\" (semantic) in a single system.\n",
    "\n",
    "**Estimated Time:** 38 minutes video + 60-90 minutes hands-on practice\n",
    "\n",
    "---\n",
    "\n",
    "### Reality Check\n",
    "\n",
    "Hybrid search is **production-level architecture** used by companies like Elasticsearch, Weaviate, and Algolia. The infrastructure trade-offs are real, but when you need exact match accuracy, it's worth it.\n",
    "\n",
    "This is advanced territory - you'll learn when to use it AND when NOT to over-engineer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Summary\n",
    "\n",
    "Run all cells above to validate your M3.4 completion before starting M4.1.\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "‚úÖ **GREEN (Ready for M4.1):**\n",
    "- All 4 checklist items pass OR sample files created for manual completion\n",
    "- You understand the hybrid search trade-offs (latency, complexity, cost)\n",
    "\n",
    "‚ö†Ô∏è **YELLOW (Action Required):**\n",
    "- Some checks failed but sample files created\n",
    "- Manual steps required: update staging_metrics.json, configure alerts, document capacity\n",
    "\n",
    "‚ùå **RED (Complete M3.4 First):**\n",
    "- No CI/CD pipeline\n",
    "- No monitoring/alerts\n",
    "- No capacity documentation\n",
    "- Debugging hybrid search will be much harder without production foundations\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Complete any failed checks** using the sample files as templates\n",
    "2. **Review the WHY hybrid search section** to understand trade-offs\n",
    "3. **Proceed to M4.1: Hybrid Search** when ready\n",
    "\n",
    "**Remember:** Module 4 assumes production deployment is working. Missing foundations make advanced techniques much harder to implement and debug.\n",
    "\n",
    "---\n",
    "\n",
    "**You're ready for advanced RAG techniques!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
